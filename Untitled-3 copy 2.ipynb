{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7670f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.41686176\n",
      "Iteration 2, loss = 1.20755760\n",
      "Iteration 3, loss = 1.04915645\n",
      "Iteration 4, loss = 0.90060113\n",
      "Iteration 5, loss = 0.75425374\n",
      "Iteration 6, loss = 0.61935583\n",
      "Iteration 7, loss = 0.51328264\n",
      "Iteration 8, loss = 0.43393833\n",
      "Iteration 9, loss = 0.37933632\n",
      "Iteration 10, loss = 0.33981331\n",
      "Iteration 11, loss = 0.31651727\n",
      "Iteration 12, loss = 0.29613295\n",
      "Iteration 13, loss = 0.28241192\n",
      "Iteration 14, loss = 0.27374308\n",
      "Iteration 15, loss = 0.26628288\n",
      "Iteration 16, loss = 0.25967191\n",
      "Iteration 17, loss = 0.25545262\n",
      "Iteration 18, loss = 0.24989943\n",
      "Iteration 19, loss = 0.25074776\n",
      "Iteration 20, loss = 0.24384788\n",
      "Iteration 21, loss = 0.24189496\n",
      "Iteration 22, loss = 0.24004578\n",
      "Iteration 23, loss = 0.23932475\n",
      "Iteration 24, loss = 0.23676712\n",
      "Iteration 25, loss = 0.23479434\n",
      "Iteration 26, loss = 0.23230697\n",
      "Iteration 27, loss = 0.23296786\n",
      "Iteration 28, loss = 0.23039119\n",
      "Iteration 29, loss = 0.22648935\n",
      "Iteration 30, loss = 0.22623554\n",
      "Iteration 31, loss = 0.22399543\n",
      "Iteration 32, loss = 0.22404210\n",
      "Iteration 33, loss = 0.22300221\n",
      "Iteration 34, loss = 0.22181147\n",
      "Iteration 35, loss = 0.22095507\n",
      "Iteration 36, loss = 0.22389162\n",
      "Iteration 37, loss = 0.21983930\n",
      "Iteration 38, loss = 0.21777853\n",
      "Iteration 39, loss = 0.21805684\n",
      "Iteration 40, loss = 0.21856951\n",
      "Iteration 41, loss = 0.21571892\n",
      "Iteration 42, loss = 0.21674620\n",
      "Iteration 43, loss = 0.21398596\n",
      "Iteration 44, loss = 0.21561444\n",
      "Iteration 45, loss = 0.21309032\n",
      "Iteration 46, loss = 0.21790855\n",
      "Iteration 47, loss = 0.21830927\n",
      "Iteration 48, loss = 0.21469678\n",
      "Iteration 49, loss = 0.21207458\n",
      "Iteration 50, loss = 0.21320952\n",
      "Iteration 51, loss = 0.21496640\n",
      "Iteration 52, loss = 0.21124323\n",
      "Iteration 53, loss = 0.20783262\n",
      "Iteration 54, loss = 0.21121361\n",
      "Iteration 55, loss = 0.21330170\n",
      "Iteration 56, loss = 0.21344547\n",
      "Iteration 57, loss = 0.20880106\n",
      "Iteration 58, loss = 0.21515886\n",
      "Iteration 59, loss = 0.20993674\n",
      "Iteration 60, loss = 0.21083105\n",
      "Iteration 61, loss = 0.21007768\n",
      "Iteration 62, loss = 0.20779125\n",
      "Iteration 63, loss = 0.20788539\n",
      "Iteration 64, loss = 0.20612641\n",
      "Iteration 65, loss = 0.20591471\n",
      "Iteration 66, loss = 0.20976268\n",
      "Iteration 67, loss = 0.20687950\n",
      "Iteration 68, loss = 0.20519434\n",
      "Iteration 69, loss = 0.20778789\n",
      "Iteration 70, loss = 0.20573954\n",
      "Iteration 71, loss = 0.20834741\n",
      "Iteration 72, loss = 0.20552117\n",
      "Iteration 73, loss = 0.20746982\n",
      "Iteration 74, loss = 0.20685731\n",
      "Iteration 75, loss = 0.20508369\n",
      "Iteration 76, loss = 0.20487535\n",
      "Iteration 77, loss = 0.20828801\n",
      "Iteration 78, loss = 0.20864388\n",
      "Iteration 79, loss = 0.20493040\n",
      "Iteration 80, loss = 0.21020025\n",
      "Iteration 81, loss = 0.20514059\n",
      "Iteration 82, loss = 0.20604686\n",
      "Iteration 83, loss = 0.20775010\n",
      "Iteration 84, loss = 0.20454931\n",
      "Iteration 85, loss = 0.20794261\n",
      "Iteration 86, loss = 0.21138405\n",
      "Iteration 87, loss = 0.20265787\n",
      "Iteration 88, loss = 0.20284160\n",
      "Iteration 89, loss = 0.20221871\n",
      "Iteration 90, loss = 0.20334844\n",
      "Iteration 91, loss = 0.20511888\n",
      "Iteration 92, loss = 0.20383521\n",
      "Iteration 93, loss = 0.20519498\n",
      "Iteration 94, loss = 0.21353127\n",
      "Iteration 95, loss = 0.20339164\n",
      "Iteration 96, loss = 0.20204800\n",
      "Iteration 97, loss = 0.20723676\n",
      "Iteration 98, loss = 0.20245813\n",
      "Iteration 99, loss = 0.20209924\n",
      "Iteration 100, loss = 0.20365641\n",
      "Iteration 1, loss = 1.31547378\n",
      "Iteration 2, loss = 1.15485378\n",
      "Iteration 3, loss = 1.01468406\n",
      "Iteration 4, loss = 0.88089314\n",
      "Iteration 5, loss = 0.76734484\n",
      "Iteration 6, loss = 0.67500228\n",
      "Iteration 7, loss = 0.59425270\n",
      "Iteration 8, loss = 0.53694581\n",
      "Iteration 9, loss = 0.48829561\n",
      "Iteration 10, loss = 0.45288532\n",
      "Iteration 11, loss = 0.42496378\n",
      "Iteration 12, loss = 0.40036411\n",
      "Iteration 13, loss = 0.38688171\n",
      "Iteration 14, loss = 0.37100962\n",
      "Iteration 15, loss = 0.35995432\n",
      "Iteration 16, loss = 0.35303646\n",
      "Iteration 17, loss = 0.34583766\n",
      "Iteration 18, loss = 0.33741785\n",
      "Iteration 19, loss = 0.32998234\n",
      "Iteration 20, loss = 0.32905872\n",
      "Iteration 21, loss = 0.32581519\n",
      "Iteration 22, loss = 0.31773512\n",
      "Iteration 23, loss = 0.31459564\n",
      "Iteration 24, loss = 0.31139642\n",
      "Iteration 25, loss = 0.30618509\n",
      "Iteration 26, loss = 0.30480555\n",
      "Iteration 27, loss = 0.30356709\n",
      "Iteration 28, loss = 0.29945465\n",
      "Iteration 29, loss = 0.29755115\n",
      "Iteration 30, loss = 0.29738576\n",
      "Iteration 31, loss = 0.29603794\n",
      "Iteration 32, loss = 0.29289299\n",
      "Iteration 33, loss = 0.29916393\n",
      "Iteration 34, loss = 0.28814038\n",
      "Iteration 35, loss = 0.28689387\n",
      "Iteration 36, loss = 0.28527064\n",
      "Iteration 37, loss = 0.28438256\n",
      "Iteration 38, loss = 0.28220070\n",
      "Iteration 39, loss = 0.28215520\n",
      "Iteration 40, loss = 0.28291824\n",
      "Iteration 41, loss = 0.27880245\n",
      "Iteration 42, loss = 0.27850605\n",
      "Iteration 43, loss = 0.27822622\n",
      "Iteration 44, loss = 0.27852734\n",
      "Iteration 45, loss = 0.27675362\n",
      "Iteration 46, loss = 0.27552548\n",
      "Iteration 47, loss = 0.27226531\n",
      "Iteration 48, loss = 0.27367141\n",
      "Iteration 49, loss = 0.27448120\n",
      "Iteration 50, loss = 0.27166941\n",
      "Iteration 51, loss = 0.27175990\n",
      "Iteration 52, loss = 0.26637490\n",
      "Iteration 53, loss = 0.26969688\n",
      "Iteration 54, loss = 0.26820085\n",
      "Iteration 55, loss = 0.26945482\n",
      "Iteration 56, loss = 0.26424144\n",
      "Iteration 57, loss = 0.26692478\n",
      "Iteration 58, loss = 0.26448055\n",
      "Iteration 59, loss = 0.26656916\n",
      "Iteration 60, loss = 0.26243952\n",
      "Iteration 61, loss = 0.26137695\n",
      "Iteration 62, loss = 0.26433560\n",
      "Iteration 63, loss = 0.26251672\n",
      "Iteration 64, loss = 0.26121764\n",
      "Iteration 65, loss = 0.25762435\n",
      "Iteration 66, loss = 0.26171772\n",
      "Iteration 67, loss = 0.25706318\n",
      "Iteration 68, loss = 0.25485772\n",
      "Iteration 69, loss = 0.25545388\n",
      "Iteration 70, loss = 0.25389740\n",
      "Iteration 71, loss = 0.25483463\n",
      "Iteration 72, loss = 0.25396463\n",
      "Iteration 73, loss = 0.25485786\n",
      "Iteration 74, loss = 0.25491068\n",
      "Iteration 75, loss = 0.25337868\n",
      "Iteration 76, loss = 0.25357853\n",
      "Iteration 77, loss = 0.25142145\n",
      "Iteration 78, loss = 0.25083421\n",
      "Iteration 79, loss = 0.24958362\n",
      "Iteration 80, loss = 0.24990981\n",
      "Iteration 81, loss = 0.24931819\n",
      "Iteration 82, loss = 0.25077687\n",
      "Iteration 83, loss = 0.24867371\n",
      "Iteration 84, loss = 0.24780691\n",
      "Iteration 85, loss = 0.25361766\n",
      "Iteration 86, loss = 0.25375488\n",
      "Iteration 87, loss = 0.25487878\n",
      "Iteration 88, loss = 0.24991743\n",
      "Iteration 89, loss = 0.24636138\n",
      "Iteration 90, loss = 0.24779791\n",
      "Iteration 91, loss = 0.24887000\n",
      "Iteration 92, loss = 0.24946971\n",
      "Iteration 93, loss = 0.24988384\n",
      "Iteration 94, loss = 0.24563537\n",
      "Iteration 95, loss = 0.24925984\n",
      "Iteration 96, loss = 0.24573839\n",
      "Iteration 97, loss = 0.24501648\n",
      "Iteration 98, loss = 0.24998872\n",
      "Iteration 99, loss = 0.24435838\n",
      "Iteration 100, loss = 0.24707051\n",
      "Iteration 1, loss = 1.32353175\n",
      "Iteration 2, loss = 1.15715936\n",
      "Iteration 3, loss = 1.01065612\n",
      "Iteration 4, loss = 0.86932408\n",
      "Iteration 5, loss = 0.73746666\n",
      "Iteration 6, loss = 0.61680713\n",
      "Iteration 7, loss = 0.53792520\n",
      "Iteration 8, loss = 0.47347885\n",
      "Iteration 9, loss = 0.43379291\n",
      "Iteration 10, loss = 0.40343287\n",
      "Iteration 11, loss = 0.38530597\n",
      "Iteration 12, loss = 0.37162019\n",
      "Iteration 13, loss = 0.35771496\n",
      "Iteration 14, loss = 0.34473201\n",
      "Iteration 15, loss = 0.34701959\n",
      "Iteration 16, loss = 0.32911588\n",
      "Iteration 17, loss = 0.32657461\n",
      "Iteration 18, loss = 0.32172404\n",
      "Iteration 19, loss = 0.31665026\n",
      "Iteration 20, loss = 0.31676948\n",
      "Iteration 21, loss = 0.30563120\n",
      "Iteration 22, loss = 0.30284281\n",
      "Iteration 23, loss = 0.30257691\n",
      "Iteration 24, loss = 0.29764700\n",
      "Iteration 25, loss = 0.29172685\n",
      "Iteration 26, loss = 0.29220691\n",
      "Iteration 27, loss = 0.28894707\n",
      "Iteration 28, loss = 0.28815468\n",
      "Iteration 29, loss = 0.28529091\n",
      "Iteration 30, loss = 0.28159846\n",
      "Iteration 31, loss = 0.27754564\n",
      "Iteration 32, loss = 0.27590235\n",
      "Iteration 33, loss = 0.27471724\n",
      "Iteration 34, loss = 0.27737037\n",
      "Iteration 35, loss = 0.27313929\n",
      "Iteration 36, loss = 0.27339667\n",
      "Iteration 37, loss = 0.27091762\n",
      "Iteration 38, loss = 0.26702880\n",
      "Iteration 39, loss = 0.26436228\n",
      "Iteration 40, loss = 0.26488426\n",
      "Iteration 41, loss = 0.26284944\n",
      "Iteration 42, loss = 0.26230685\n",
      "Iteration 43, loss = 0.25926360\n",
      "Iteration 44, loss = 0.26062528\n",
      "Iteration 45, loss = 0.25668948\n",
      "Iteration 46, loss = 0.26420810\n",
      "Iteration 47, loss = 0.25521143\n",
      "Iteration 48, loss = 0.25627637\n",
      "Iteration 49, loss = 0.25960616\n",
      "Iteration 50, loss = 0.25072914\n",
      "Iteration 51, loss = 0.25221471\n",
      "Iteration 52, loss = 0.25851236\n",
      "Iteration 53, loss = 0.25016977\n",
      "Iteration 54, loss = 0.24994928\n",
      "Iteration 55, loss = 0.24956163\n",
      "Iteration 56, loss = 0.24651204\n",
      "Iteration 57, loss = 0.25224193\n",
      "Iteration 58, loss = 0.25608147\n",
      "Iteration 59, loss = 0.24633221\n",
      "Iteration 60, loss = 0.24424059\n",
      "Iteration 61, loss = 0.24386634\n",
      "Iteration 62, loss = 0.24219810\n",
      "Iteration 63, loss = 0.24062001\n",
      "Iteration 64, loss = 0.23923885\n",
      "Iteration 65, loss = 0.24083864\n",
      "Iteration 66, loss = 0.23897543\n",
      "Iteration 67, loss = 0.23857758\n",
      "Iteration 68, loss = 0.23841547\n",
      "Iteration 69, loss = 0.23740595\n",
      "Iteration 70, loss = 0.23804782\n",
      "Iteration 71, loss = 0.24047398\n",
      "Iteration 72, loss = 0.23563759\n",
      "Iteration 73, loss = 0.23458385\n",
      "Iteration 74, loss = 0.23560897\n",
      "Iteration 75, loss = 0.23538883\n",
      "Iteration 76, loss = 0.23619702\n",
      "Iteration 77, loss = 0.23439771\n",
      "Iteration 78, loss = 0.23242451\n",
      "Iteration 79, loss = 0.23549900\n",
      "Iteration 80, loss = 0.23180508\n",
      "Iteration 81, loss = 0.22897624\n",
      "Iteration 82, loss = 0.23005089\n",
      "Iteration 83, loss = 0.23124645\n",
      "Iteration 84, loss = 0.23047693\n",
      "Iteration 85, loss = 0.23333472\n",
      "Iteration 86, loss = 0.23030529\n",
      "Iteration 87, loss = 0.23235212\n",
      "Iteration 88, loss = 0.23332763\n",
      "Iteration 89, loss = 0.22825842\n",
      "Iteration 90, loss = 0.22756575\n",
      "Iteration 91, loss = 0.22515326\n",
      "Iteration 92, loss = 0.22955859\n",
      "Iteration 93, loss = 0.23306726\n",
      "Iteration 94, loss = 0.22554584\n",
      "Iteration 95, loss = 0.22386754\n",
      "Iteration 96, loss = 0.22651863\n",
      "Iteration 97, loss = 0.22440559\n",
      "Iteration 98, loss = 0.22242106\n",
      "Iteration 99, loss = 0.22220109\n",
      "Iteration 100, loss = 0.22410970\n",
      "Iteration 1, loss = 1.41047743\n",
      "Iteration 2, loss = 1.24505040\n",
      "Iteration 3, loss = 1.12201575\n",
      "Iteration 4, loss = 1.00594764\n",
      "Iteration 5, loss = 0.89248640\n",
      "Iteration 6, loss = 0.79399657\n",
      "Iteration 7, loss = 0.70752405\n",
      "Iteration 8, loss = 0.63125674\n",
      "Iteration 9, loss = 0.57028642\n",
      "Iteration 10, loss = 0.50546546\n",
      "Iteration 11, loss = 0.46710395\n",
      "Iteration 12, loss = 0.43716571\n",
      "Iteration 13, loss = 0.40389591\n",
      "Iteration 14, loss = 0.38284240\n",
      "Iteration 15, loss = 0.36622313\n",
      "Iteration 16, loss = 0.35506839\n",
      "Iteration 17, loss = 0.35211657\n",
      "Iteration 18, loss = 0.33949572\n",
      "Iteration 19, loss = 0.33308200\n",
      "Iteration 20, loss = 0.32698411\n",
      "Iteration 21, loss = 0.31911636\n",
      "Iteration 22, loss = 0.31933170\n",
      "Iteration 23, loss = 0.31409211\n",
      "Iteration 24, loss = 0.30994868\n",
      "Iteration 25, loss = 0.30877095\n",
      "Iteration 26, loss = 0.30186408\n",
      "Iteration 27, loss = 0.30029178\n",
      "Iteration 28, loss = 0.30234116\n",
      "Iteration 29, loss = 0.29501692\n",
      "Iteration 30, loss = 0.29460961\n",
      "Iteration 31, loss = 0.29867749\n",
      "Iteration 32, loss = 0.28888460\n",
      "Iteration 33, loss = 0.28724030\n",
      "Iteration 34, loss = 0.29072521\n",
      "Iteration 35, loss = 0.28531886\n",
      "Iteration 36, loss = 0.28909467\n",
      "Iteration 37, loss = 0.27951027\n",
      "Iteration 38, loss = 0.28190484\n",
      "Iteration 39, loss = 0.28069252\n",
      "Iteration 40, loss = 0.27764832\n",
      "Iteration 41, loss = 0.27559894\n",
      "Iteration 42, loss = 0.27234182\n",
      "Iteration 43, loss = 0.27504583\n",
      "Iteration 44, loss = 0.27170103\n",
      "Iteration 45, loss = 0.27880812\n",
      "Iteration 46, loss = 0.26768257\n",
      "Iteration 47, loss = 0.27194622\n",
      "Iteration 48, loss = 0.26738595\n",
      "Iteration 49, loss = 0.26519134\n",
      "Iteration 50, loss = 0.26798127\n",
      "Iteration 51, loss = 0.26344025\n",
      "Iteration 52, loss = 0.27157452\n",
      "Iteration 53, loss = 0.26612555\n",
      "Iteration 54, loss = 0.26853430\n",
      "Iteration 55, loss = 0.26101986\n",
      "Iteration 56, loss = 0.25933852\n",
      "Iteration 57, loss = 0.25958667\n",
      "Iteration 58, loss = 0.25857103\n",
      "Iteration 59, loss = 0.26092888\n",
      "Iteration 60, loss = 0.26044647\n",
      "Iteration 61, loss = 0.25738768\n",
      "Iteration 62, loss = 0.25488641\n",
      "Iteration 63, loss = 0.26480225\n",
      "Iteration 64, loss = 0.25560294\n",
      "Iteration 65, loss = 0.25867330\n",
      "Iteration 66, loss = 0.25454173\n",
      "Iteration 67, loss = 0.25413268\n",
      "Iteration 68, loss = 0.25146637\n",
      "Iteration 69, loss = 0.25188220\n",
      "Iteration 70, loss = 0.25156395\n",
      "Iteration 71, loss = 0.25016328\n",
      "Iteration 72, loss = 0.25069580\n",
      "Iteration 73, loss = 0.25087852\n",
      "Iteration 74, loss = 0.24930354\n",
      "Iteration 75, loss = 0.25230460\n",
      "Iteration 76, loss = 0.25103624\n",
      "Iteration 77, loss = 0.25261668\n",
      "Iteration 78, loss = 0.24649516\n",
      "Iteration 79, loss = 0.25006808\n",
      "Iteration 80, loss = 0.24739781\n",
      "Iteration 81, loss = 0.24901067\n",
      "Iteration 82, loss = 0.24445488\n",
      "Iteration 83, loss = 0.24517284\n",
      "Iteration 84, loss = 0.25349948\n",
      "Iteration 85, loss = 0.24656429\n",
      "Iteration 86, loss = 0.24487074\n",
      "Iteration 87, loss = 0.24390260\n",
      "Iteration 88, loss = 0.24346760\n",
      "Iteration 89, loss = 0.24466760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 90, loss = 0.24430356\n",
      "Iteration 91, loss = 0.24477480\n",
      "Iteration 92, loss = 0.24651959\n",
      "Iteration 93, loss = 0.24330693\n",
      "Iteration 94, loss = 0.24390071\n",
      "Iteration 95, loss = 0.23986873\n",
      "Iteration 96, loss = 0.24448298\n",
      "Iteration 97, loss = 0.24220003\n",
      "Iteration 98, loss = 0.23829527\n",
      "Iteration 99, loss = 0.24146217\n",
      "Iteration 100, loss = 0.24206401\n",
      "Iteration 1, loss = 1.43757149\n",
      "Iteration 2, loss = 1.22713339\n",
      "Iteration 3, loss = 1.05196512\n",
      "Iteration 4, loss = 0.89239806\n",
      "Iteration 5, loss = 0.75201723\n",
      "Iteration 6, loss = 0.63812141\n",
      "Iteration 7, loss = 0.54549894\n",
      "Iteration 8, loss = 0.46803186\n",
      "Iteration 9, loss = 0.41348760\n",
      "Iteration 10, loss = 0.37291158\n",
      "Iteration 11, loss = 0.34500663\n",
      "Iteration 12, loss = 0.32778510\n",
      "Iteration 13, loss = 0.31122803\n",
      "Iteration 14, loss = 0.29457710\n",
      "Iteration 15, loss = 0.28781123\n",
      "Iteration 16, loss = 0.27999860\n",
      "Iteration 17, loss = 0.27253917\n",
      "Iteration 18, loss = 0.26662933\n",
      "Iteration 19, loss = 0.25965717\n",
      "Iteration 20, loss = 0.26023593\n",
      "Iteration 21, loss = 0.25479453\n",
      "Iteration 22, loss = 0.25124820\n",
      "Iteration 23, loss = 0.24434060\n",
      "Iteration 24, loss = 0.24495225\n",
      "Iteration 25, loss = 0.24216744\n",
      "Iteration 26, loss = 0.23959998\n",
      "Iteration 27, loss = 0.23604914\n",
      "Iteration 28, loss = 0.23446838\n",
      "Iteration 29, loss = 0.23009255\n",
      "Iteration 30, loss = 0.22820112\n",
      "Iteration 31, loss = 0.22648709\n",
      "Iteration 32, loss = 0.22631264\n",
      "Iteration 33, loss = 0.22810093\n",
      "Iteration 34, loss = 0.22658471\n",
      "Iteration 35, loss = 0.22610112\n",
      "Iteration 36, loss = 0.22539056\n",
      "Iteration 37, loss = 0.22147588\n",
      "Iteration 38, loss = 0.21833992\n",
      "Iteration 39, loss = 0.21719574\n",
      "Iteration 40, loss = 0.21703992\n",
      "Iteration 41, loss = 0.21522675\n",
      "Iteration 42, loss = 0.21541016\n",
      "Iteration 43, loss = 0.21415103\n",
      "Iteration 44, loss = 0.21556866\n",
      "Iteration 45, loss = 0.21325296\n",
      "Iteration 46, loss = 0.21239662\n",
      "Iteration 47, loss = 0.21611929\n",
      "Iteration 48, loss = 0.21452287\n",
      "Iteration 49, loss = 0.21105838\n",
      "Iteration 50, loss = 0.20855878\n",
      "Iteration 51, loss = 0.21338980\n",
      "Iteration 52, loss = 0.20896906\n",
      "Iteration 53, loss = 0.20823461\n",
      "Iteration 54, loss = 0.20856091\n",
      "Iteration 55, loss = 0.20757367\n",
      "Iteration 56, loss = 0.20611159\n",
      "Iteration 57, loss = 0.20874340\n",
      "Iteration 58, loss = 0.20743239\n",
      "Iteration 59, loss = 0.21547137\n",
      "Iteration 60, loss = 0.20928065\n",
      "Iteration 61, loss = 0.21260772\n",
      "Iteration 62, loss = 0.22349631\n",
      "Iteration 63, loss = 0.20618601\n",
      "Iteration 64, loss = 0.20478246\n",
      "Iteration 65, loss = 0.20298469\n",
      "Iteration 66, loss = 0.20622951\n",
      "Iteration 67, loss = 0.20620361\n",
      "Iteration 68, loss = 0.20509925\n",
      "Iteration 69, loss = 0.20429089\n",
      "Iteration 70, loss = 0.20284366\n",
      "Iteration 71, loss = 0.20334890\n",
      "Iteration 72, loss = 0.20137065\n",
      "Iteration 73, loss = 0.20499782\n",
      "Iteration 74, loss = 0.20485641\n",
      "Iteration 75, loss = 0.20223290\n",
      "Iteration 76, loss = 0.20418149\n",
      "Iteration 77, loss = 0.20125370\n",
      "Iteration 78, loss = 0.20021475\n",
      "Iteration 79, loss = 0.20333653\n",
      "Iteration 80, loss = 0.20055279\n",
      "Iteration 81, loss = 0.20751803\n",
      "Iteration 82, loss = 0.20029803\n",
      "Iteration 83, loss = 0.20559250\n",
      "Iteration 84, loss = 0.20699667\n",
      "Iteration 85, loss = 0.20320508\n",
      "Iteration 86, loss = 0.20129301\n",
      "Iteration 87, loss = 0.20436977\n",
      "Iteration 88, loss = 0.20481431\n",
      "Iteration 89, loss = 0.20025231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Train Accuracy: 91.0%\n",
      "Train Accuracy: 88.0%\n",
      "Train Accuracy: 88.0%\n",
      "INPUT:  [[1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[{'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.266, 0.552, 0.074, 0.109]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.262, 0.283, 0.205, 0.25 ]), 'nn': array([0.208, 0.634, 0.066, 0.092]), 'svc': array([0.361, 0.531, 0.024, 0.085]), 'nb': array([0.232, 0.759, 0.001, 0.008])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.289, 0.353, 0.276]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.089, 0.353, 0.194, 0.363]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.448, 0.091, 0.374, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.318, 0.097, 0.484, 0.101]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.104, 0.084, 0.154, 0.659]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.081, 0.091, 0.075, 0.753]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.674, 0.138, 0.079, 0.109]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.089, 0.102, 0.609, 0.201]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.225, 0.239, 0.264, 0.272]), 'nn': array([0.078, 0.091, 0.735, 0.095]), 'svc': array([0.043, 0.031, 0.626, 0.3  ]), 'nb': array([0.01 , 0.045, 0.809, 0.136])}}, {'ensemble_proba': array([0.109, 0.532, 0.08 , 0.279]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.232, 0.278, 0.218, 0.272]), 'nn': array([0.092, 0.454, 0.075, 0.379]), 'svc': array([0.093, 0.592, 0.023, 0.293]), 'nb': array([0.02 , 0.802, 0.002, 0.175])}}, {'ensemble_proba': array([0.083, 0.289, 0.353, 0.276]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.089, 0.353, 0.194, 0.363]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.434, 0.229, 0.093, 0.244]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.499, 0.103, 0.074, 0.324]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.448, 0.091, 0.374, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.318, 0.097, 0.484, 0.101]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.199, 0.594, 0.094, 0.113]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.267, 0.234, 0.251]), 'nn': array([0.097, 0.728, 0.07 , 0.105]), 'svc': array([0.281, 0.603, 0.047, 0.069]), 'nb': array([0.17 , 0.779, 0.024, 0.027])}}, {'ensemble_proba': array([0.448, 0.091, 0.374, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.318, 0.097, 0.484, 0.101]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.213, 0.082, 0.56 , 0.145]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.259, 0.217, 0.258, 0.267]), 'nn': array([0.104, 0.092, 0.709, 0.095]), 'svc': array([0.245, 0.011, 0.609, 0.135]), 'nb': array([0.243, 0.007, 0.665, 0.085])}}, {'ensemble_proba': array([0.448, 0.091, 0.374, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.318, 0.097, 0.484, 0.101]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.168, 0.644, 0.093, 0.095]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.089, 0.753, 0.066, 0.092]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.168, 0.644, 0.093, 0.095]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.089, 0.753, 0.066, 0.092]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.168, 0.644, 0.093, 0.095]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.089, 0.753, 0.066, 0.092]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.674, 0.138, 0.079, 0.109]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.448, 0.091, 0.374, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.318, 0.097, 0.484, 0.101]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.081, 0.14 , 0.095, 0.684]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.213, 0.248, 0.218, 0.32 ]), 'nn': array([0.08 , 0.098, 0.069, 0.753]), 'svc': array([0.031, 0.193, 0.089, 0.687]), 'nb': array([0.001, 0.021, 0.003, 0.976])}}, {'ensemble_proba': array([0.088, 0.661, 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.077, 0.766, 0.065, 0.092]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.668, 0.137, 0.112, 0.083]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.297, 0.244, 0.244, 0.215]), 'nn': array([0.754, 0.091, 0.065, 0.09 ]), 'svc': array([0.661, 0.195, 0.117, 0.027]), 'nb': array([0.962, 0.018, 0.02 , 0.   ])}}, {'ensemble_proba': array([0.086, 0.124, 0.65 , 0.14 ]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.232, 0.238, 0.273, 0.258]), 'nn': array([0.08 , 0.091, 0.703, 0.126]), 'svc': array([0.03 , 0.156, 0.683, 0.131]), 'nb': array([0.004, 0.01 , 0.943, 0.043])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.088, 0.661, 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.077, 0.766, 0.065, 0.092]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.183, 0.097, 0.084, 0.637]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.244, 0.236, 0.225, 0.295]), 'nn': array([0.092, 0.092, 0.072, 0.745]), 'svc': array([0.296, 0.046, 0.026, 0.632]), 'nb': array([0.1  , 0.014, 0.011, 0.875])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.434, 0.229, 0.093, 0.244]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.499, 0.103, 0.074, 0.324]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.124, 0.119, 0.162, 0.595]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.104, 0.18 , 0.177, 0.539]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.629, 0.1  , 0.09 , 0.182]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.27 , 0.238, 0.223, 0.269]), 'nn': array([0.753, 0.091, 0.066, 0.091]), 'svc': array([0.625, 0.025, 0.05 , 0.3  ]), 'nb': array([0.868, 0.046, 0.02 , 0.066])}}, {'ensemble_proba': array([0.088, 0.661, 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.077, 0.766, 0.065, 0.092]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.104, 0.084, 0.154, 0.659]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.081, 0.091, 0.075, 0.753]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.399, 0.311, 0.204, 0.086]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.262, 0.255, 0.256, 0.227]), 'nn': array([0.58 , 0.256, 0.075, 0.09 ]), 'svc': array([0.368, 0.416, 0.19 , 0.026]), 'nb': array([0.387, 0.316, 0.294, 0.003])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.106, 0.076, 0.648, 0.17 ]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.246, 0.205, 0.284, 0.265]), 'nn': array([0.078, 0.089, 0.739, 0.094]), 'svc': array([0.085, 0.01 , 0.608, 0.296]), 'nb': array([0.013, 0.   , 0.96 , 0.027])}}, {'ensemble_proba': array([0.088, 0.661, 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.077, 0.766, 0.065, 0.092]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.156, 0.085, 0.676, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.269, 0.209, 0.312, 0.21 ]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.271, 0.044, 0.657, 0.027]), 'nb': array([0.007, 0.   , 0.993, 0.   ])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.592, 0.086, 0.098, 0.225]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.272, 0.224, 0.227, 0.277]), 'nn': array([0.733, 0.091, 0.072, 0.104]), 'svc': array([0.555, 0.016, 0.068, 0.361]), 'nb': array([0.808, 0.012, 0.023, 0.157])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.432, 0.137, 0.075, 0.356]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.248, 0.203, 0.295]), 'nn': array([0.611, 0.103, 0.071, 0.215]), 'svc': array([0.508, 0.09 , 0.024, 0.378]), 'nb': array([0.355, 0.106, 0.001, 0.538])}}, {'ensemble_proba': array([0.084, 0.157, 0.648, 0.112]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.078, 0.101, 0.725, 0.096]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.089, 0.102, 0.609, 0.201]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.225, 0.239, 0.264, 0.272]), 'nn': array([0.078, 0.091, 0.735, 0.095]), 'svc': array([0.043, 0.031, 0.626, 0.3  ]), 'nb': array([0.01 , 0.045, 0.809, 0.136])}}, {'ensemble_proba': array([0.124, 0.119, 0.162, 0.595]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.104, 0.18 , 0.177, 0.539]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.124, 0.119, 0.162, 0.595]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.104, 0.18 , 0.177, 0.539]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.084, 0.157, 0.648, 0.112]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.078, 0.101, 0.725, 0.096]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.088, 0.661, 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.077, 0.766, 0.065, 0.092]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.088, 0.661, 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.077, 0.766, 0.065, 0.092]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.434, 0.229, 0.093, 0.244]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.499, 0.103, 0.074, 0.324]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.657, 0.075, 0.112, 0.156]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.295, 0.204, 0.24 , 0.261]), 'nn': array([0.756, 0.086, 0.067, 0.091]), 'svc': array([0.608, 0.011, 0.121, 0.26 ]), 'nb': array([0.968, 0.   , 0.02 , 0.011])}}, {'ensemble_proba': array([0.156, 0.085, 0.676, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.269, 0.209, 0.312, 0.21 ]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.271, 0.044, 0.657, 0.027]), 'nb': array([0.007, 0.   , 0.993, 0.   ])}}, {'ensemble_proba': array([0.175, 0.452, 0.133, 0.241]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.252, 0.244, 0.255]), 'nn': array([0.164, 0.553, 0.096, 0.186]), 'svc': array([0.082, 0.591, 0.037, 0.291]), 'nb': array([0.205, 0.41 , 0.155, 0.23 ])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.177, 0.09 , 0.649]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.211, 0.263, 0.214, 0.313]), 'nn': array([0.08 , 0.133, 0.069, 0.717]), 'svc': array([0.041, 0.223, 0.075, 0.662]), 'nb': array([0.001, 0.091, 0.003, 0.905])}}, {'ensemble_proba': array([0.124, 0.119, 0.162, 0.595]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.104, 0.18 , 0.177, 0.539]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.081, 0.14 , 0.095, 0.684]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.213, 0.248, 0.218, 0.32 ]), 'nn': array([0.08 , 0.098, 0.069, 0.753]), 'svc': array([0.031, 0.193, 0.089, 0.687]), 'nb': array([0.001, 0.021, 0.003, 0.976])}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 0, 3, 2, 0, 3, 0, 2, 1, 2, 0, 0, 2, 3, 1, 0, 0, 2, 0, 1,\n",
       "       2, 3, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 0, 0, 2, 0, 1, 3, 1, 0, 2,\n",
       "       3, 1, 3, 1, 0, 3, 0, 1, 0, 3, 3, 3, 0, 0, 0, 2, 1, 2, 1, 1, 2, 0,\n",
       "       0, 0, 0, 2, 1, 3, 2, 2, 3, 3, 1, 3, 2, 1, 3, 1, 1, 0, 3, 3, 0, 2,\n",
       "       1, 0, 1, 3, 3, 2, 1, 3, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import classifierAgents\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "file = '/Users/youssefawad/Documents/Kings/term_2/6CCS3ML1_Machine_Learning/coursework/cw1_pacman/good-moves.txt'\n",
    "\n",
    "data, target = classifierAgents.loadData(file)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "from classifier import Classifier\n",
    "\n",
    "clf = Classifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbd4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  [[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[{'ensemble_proba': array([0.448, 0.091, 0.374, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.318, 0.097, 0.484, 0.101]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.121, 0.129, 0.666, 0.084]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.248, 0.245, 0.289, 0.217]), 'nn': array([0.081, 0.094, 0.733, 0.092]), 'svc': array([0.143, 0.156, 0.674, 0.027]), 'nb': array([0.013, 0.021, 0.965, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.084, 0.157, 0.648, 0.112]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.078, 0.101, 0.725, 0.096]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.434, 0.229, 0.093, 0.244]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.499, 0.103, 0.074, 0.324]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.159, 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.077, 0.089, 0.743, 0.091]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.175, 0.452, 0.133, 0.241]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.252, 0.244, 0.255]), 'nn': array([0.164, 0.553, 0.096, 0.186]), 'svc': array([0.082, 0.591, 0.037, 0.291]), 'nb': array([0.205, 0.41 , 0.155, 0.23 ])}}, {'ensemble_proba': array([0.674, 0.138, 0.079, 0.109]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.759, 0.086, 0.065, 0.09 ]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.088, 0.661, 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.077, 0.766, 0.065, 0.092]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.289, 0.353, 0.276]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.089, 0.353, 0.194, 0.363]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.078, 0.103, 0.221, 0.598]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.203, 0.24 , 0.248, 0.309]), 'nn': array([0.083, 0.106, 0.182, 0.629]), 'svc': array([0.026, 0.045, 0.326, 0.602]), 'nb': array([0.   , 0.02 , 0.127, 0.853])}}, {'ensemble_proba': array([0.104, 0.084, 0.154, 0.659]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.081, 0.091, 0.075, 0.753]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.629, 0.1  , 0.09 , 0.182]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.27 , 0.238, 0.223, 0.269]), 'nn': array([0.753, 0.091, 0.066, 0.091]), 'svc': array([0.625, 0.025, 0.05 , 0.3  ]), 'nb': array([0.868, 0.046, 0.02 , 0.066])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.088, 0.661, 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.077, 0.766, 0.065, 0.092]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.448, 0.091, 0.374, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.318, 0.097, 0.484, 0.101]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.124, 0.119, 0.162, 0.595]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.104, 0.18 , 0.177, 0.539]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.083, 0.289, 0.353, 0.276]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.089, 0.353, 0.194, 0.363]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.083, 0.3  , 0.076, 0.541]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.196, 0.287, 0.19 , 0.327]), 'nn': array([0.086, 0.324, 0.073, 0.517]), 'svc': array([0.051, 0.255, 0.043, 0.651]), 'nb': array([0.   , 0.333, 0.   , 0.667])}}, {'ensemble_proba': array([0.082, 0.164, 0.076, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.079, 0.092, 0.068, 0.761]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.08 , 0.686, 0.068, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}]\n",
      "Test Accuracy: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "accuracy = np.mean(preds == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b9e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  [[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[{'ensemble_proba': array([0.448, 0.091, 0.374, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.318, 0.097, 0.484, 0.101]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f6f963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d8e6d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.46142226\n",
      "Iteration 2, loss = 1.30162642\n",
      "Iteration 3, loss = 1.15464525\n",
      "Iteration 4, loss = 1.01076295\n",
      "Iteration 5, loss = 0.88813165\n",
      "Iteration 6, loss = 0.77500811\n",
      "Iteration 7, loss = 0.67484410\n",
      "Iteration 8, loss = 0.59172008\n",
      "Iteration 9, loss = 0.52075591\n",
      "Iteration 10, loss = 0.46057645\n",
      "Iteration 11, loss = 0.40823319\n",
      "Iteration 12, loss = 0.36799589\n",
      "Iteration 13, loss = 0.34381285\n",
      "Iteration 14, loss = 0.31139273\n",
      "Iteration 15, loss = 0.29902341\n",
      "Iteration 16, loss = 0.28776013\n",
      "Iteration 17, loss = 0.27771542\n",
      "Iteration 18, loss = 0.26920550\n",
      "Iteration 19, loss = 0.26653362\n",
      "Iteration 20, loss = 0.26502016\n",
      "Iteration 21, loss = 0.25560765\n",
      "Iteration 22, loss = 0.25347256\n",
      "Iteration 23, loss = 0.25033314\n",
      "Iteration 24, loss = 0.24864776\n",
      "Iteration 25, loss = 0.24600580\n",
      "Iteration 26, loss = 0.24319964\n",
      "Iteration 27, loss = 0.24390113\n",
      "Iteration 28, loss = 0.24493120\n",
      "Iteration 29, loss = 0.23803227\n",
      "Iteration 30, loss = 0.23707187\n",
      "Iteration 31, loss = 0.23821438\n",
      "Iteration 32, loss = 0.23211152\n",
      "Iteration 33, loss = 0.23465417\n",
      "Iteration 34, loss = 0.23414318\n",
      "Iteration 35, loss = 0.23359051\n",
      "Iteration 36, loss = 0.23128222\n",
      "Iteration 37, loss = 0.22746072\n",
      "Iteration 38, loss = 0.23200012\n",
      "Iteration 39, loss = 0.22533872\n",
      "Iteration 40, loss = 0.22670512\n",
      "Iteration 41, loss = 0.22732506\n",
      "Iteration 42, loss = 0.22817456\n",
      "Iteration 43, loss = 0.23115915\n",
      "Iteration 44, loss = 0.22556081\n",
      "Iteration 45, loss = 0.22065628\n",
      "Iteration 46, loss = 0.22107704\n",
      "Iteration 47, loss = 0.22372505\n",
      "Iteration 48, loss = 0.22013469\n",
      "Iteration 49, loss = 0.22403264\n",
      "Iteration 50, loss = 0.22038272\n",
      "Iteration 51, loss = 0.21875817\n",
      "Iteration 52, loss = 0.21712601\n",
      "Iteration 53, loss = 0.21894444\n",
      "Iteration 54, loss = 0.21895025\n",
      "Iteration 55, loss = 0.21752177\n",
      "Iteration 56, loss = 0.21533273\n",
      "Iteration 57, loss = 0.21573012\n",
      "Iteration 58, loss = 0.21516003\n",
      "Iteration 59, loss = 0.21395428\n",
      "Iteration 60, loss = 0.21618431\n",
      "Iteration 61, loss = 0.21619844\n",
      "Iteration 62, loss = 0.21691034\n",
      "Iteration 63, loss = 0.21509292\n",
      "Iteration 64, loss = 0.21547458\n",
      "Iteration 65, loss = 0.21390566\n",
      "Iteration 66, loss = 0.21393704\n",
      "Iteration 67, loss = 0.21299726\n",
      "Iteration 68, loss = 0.21207471\n",
      "Iteration 69, loss = 0.21070290\n",
      "Iteration 70, loss = 0.21640716\n",
      "Iteration 71, loss = 0.21442069\n",
      "Iteration 72, loss = 0.21730228\n",
      "Iteration 73, loss = 0.21298097\n",
      "Iteration 74, loss = 0.21201966\n",
      "Iteration 75, loss = 0.20989538\n",
      "Iteration 76, loss = 0.21153486\n",
      "Iteration 77, loss = 0.21058876\n",
      "Iteration 78, loss = 0.20810043\n",
      "Iteration 79, loss = 0.21066748\n",
      "Iteration 80, loss = 0.21388372\n",
      "Iteration 81, loss = 0.21165760\n",
      "Iteration 82, loss = 0.21089283\n",
      "Iteration 83, loss = 0.20987995\n",
      "Iteration 84, loss = 0.21139820\n",
      "Iteration 85, loss = 0.21317218\n",
      "Iteration 86, loss = 0.21094041\n",
      "Iteration 87, loss = 0.21556575\n",
      "Iteration 88, loss = 0.20709927\n",
      "Iteration 89, loss = 0.21039761\n",
      "Iteration 90, loss = 0.20975108\n",
      "Iteration 91, loss = 0.20591825\n",
      "Iteration 92, loss = 0.20721276\n",
      "Iteration 93, loss = 0.21126642\n",
      "Iteration 94, loss = 0.20684267\n",
      "Iteration 95, loss = 0.20882604\n",
      "Iteration 96, loss = 0.21406533\n",
      "Iteration 97, loss = 0.21475396\n",
      "Iteration 98, loss = 0.20885885\n",
      "Iteration 99, loss = 0.20836980\n",
      "Iteration 100, loss = 0.20917688\n",
      "Iteration 1, loss = 1.23241502\n",
      "Iteration 2, loss = 1.07934846\n",
      "Iteration 3, loss = 0.95860891\n",
      "Iteration 4, loss = 0.84867152\n",
      "Iteration 5, loss = 0.74166594\n",
      "Iteration 6, loss = 0.63935413\n",
      "Iteration 7, loss = 0.55825562\n",
      "Iteration 8, loss = 0.48601662\n",
      "Iteration 9, loss = 0.43534268\n",
      "Iteration 10, loss = 0.40026068\n",
      "Iteration 11, loss = 0.37423504\n",
      "Iteration 12, loss = 0.35263143\n",
      "Iteration 13, loss = 0.33624715\n",
      "Iteration 14, loss = 0.32911472\n",
      "Iteration 15, loss = 0.31970522\n",
      "Iteration 16, loss = 0.31404927\n",
      "Iteration 17, loss = 0.30588378\n",
      "Iteration 18, loss = 0.30016182\n",
      "Iteration 19, loss = 0.29932053\n",
      "Iteration 20, loss = 0.29753151\n",
      "Iteration 21, loss = 0.29045419\n",
      "Iteration 22, loss = 0.28764304\n",
      "Iteration 23, loss = 0.28565075\n",
      "Iteration 24, loss = 0.28324983\n",
      "Iteration 25, loss = 0.27954830\n",
      "Iteration 26, loss = 0.27679811\n",
      "Iteration 27, loss = 0.27501430\n",
      "Iteration 28, loss = 0.27329622\n",
      "Iteration 29, loss = 0.27275792\n",
      "Iteration 30, loss = 0.26815247\n",
      "Iteration 31, loss = 0.27453665\n",
      "Iteration 32, loss = 0.26831712\n",
      "Iteration 33, loss = 0.26447216\n",
      "Iteration 34, loss = 0.26394733\n",
      "Iteration 35, loss = 0.26279837\n",
      "Iteration 36, loss = 0.25922726\n",
      "Iteration 37, loss = 0.25820248\n",
      "Iteration 38, loss = 0.25791311\n",
      "Iteration 39, loss = 0.25497060\n",
      "Iteration 40, loss = 0.25731592\n",
      "Iteration 41, loss = 0.25824359\n",
      "Iteration 42, loss = 0.25147094\n",
      "Iteration 43, loss = 0.25294110\n",
      "Iteration 44, loss = 0.25193180\n",
      "Iteration 45, loss = 0.25187489\n",
      "Iteration 46, loss = 0.25132216\n",
      "Iteration 47, loss = 0.24764140\n",
      "Iteration 48, loss = 0.24924377\n",
      "Iteration 49, loss = 0.24882849\n",
      "Iteration 50, loss = 0.24820818\n",
      "Iteration 51, loss = 0.24572501\n",
      "Iteration 52, loss = 0.24787404\n",
      "Iteration 53, loss = 0.25232124\n",
      "Iteration 54, loss = 0.24603655\n",
      "Iteration 55, loss = 0.24221213\n",
      "Iteration 56, loss = 0.24381216\n",
      "Iteration 57, loss = 0.24404083\n",
      "Iteration 58, loss = 0.24753355\n",
      "Iteration 59, loss = 0.24329791\n",
      "Iteration 60, loss = 0.24787634\n",
      "Iteration 61, loss = 0.24075876\n",
      "Iteration 62, loss = 0.24181547\n",
      "Iteration 63, loss = 0.24767672\n",
      "Iteration 64, loss = 0.24046848\n",
      "Iteration 65, loss = 0.23853820\n",
      "Iteration 66, loss = 0.24103968\n",
      "Iteration 67, loss = 0.24153813\n",
      "Iteration 68, loss = 0.24039350\n",
      "Iteration 69, loss = 0.23916983\n",
      "Iteration 70, loss = 0.24472156\n",
      "Iteration 71, loss = 0.23935424\n",
      "Iteration 72, loss = 0.23576518\n",
      "Iteration 73, loss = 0.23845683\n",
      "Iteration 74, loss = 0.23787335\n",
      "Iteration 75, loss = 0.23682558\n",
      "Iteration 76, loss = 0.23751128\n",
      "Iteration 77, loss = 0.23645591\n",
      "Iteration 78, loss = 0.23762113\n",
      "Iteration 79, loss = 0.23621775\n",
      "Iteration 80, loss = 0.23576994\n",
      "Iteration 81, loss = 0.23480019\n",
      "Iteration 82, loss = 0.23795545\n",
      "Iteration 83, loss = 0.23380305\n",
      "Iteration 84, loss = 0.23539174\n",
      "Iteration 85, loss = 0.23815629\n",
      "Iteration 86, loss = 0.23143718\n",
      "Iteration 87, loss = 0.23869079\n",
      "Iteration 88, loss = 0.23587888\n",
      "Iteration 89, loss = 0.23374007\n",
      "Iteration 90, loss = 0.23093960\n",
      "Iteration 91, loss = 0.23342219\n",
      "Iteration 92, loss = 0.23351087\n",
      "Iteration 93, loss = 0.23241958\n",
      "Iteration 94, loss = 0.23531037\n",
      "Iteration 95, loss = 0.23618430\n",
      "Iteration 96, loss = 0.23143849\n",
      "Iteration 97, loss = 0.23989544\n",
      "Iteration 98, loss = 0.23022215\n",
      "Iteration 99, loss = 0.22993583\n",
      "Iteration 100, loss = 0.23282068\n",
      "Iteration 1, loss = 1.42524930\n",
      "Iteration 2, loss = 1.26489793\n",
      "Iteration 3, loss = 1.14104672\n",
      "Iteration 4, loss = 1.01413526\n",
      "Iteration 5, loss = 0.89722355\n",
      "Iteration 6, loss = 0.78509611\n",
      "Iteration 7, loss = 0.70003083\n",
      "Iteration 8, loss = 0.64323980\n",
      "Iteration 9, loss = 0.58594712\n",
      "Iteration 10, loss = 0.54527997\n",
      "Iteration 11, loss = 0.50862258\n",
      "Iteration 12, loss = 0.48504950\n",
      "Iteration 13, loss = 0.44882788\n",
      "Iteration 14, loss = 0.41697310\n",
      "Iteration 15, loss = 0.39902666\n",
      "Iteration 16, loss = 0.37821076\n",
      "Iteration 17, loss = 0.36450266\n",
      "Iteration 18, loss = 0.35220787\n",
      "Iteration 19, loss = 0.33958548\n",
      "Iteration 20, loss = 0.33439024\n",
      "Iteration 21, loss = 0.32396568\n",
      "Iteration 22, loss = 0.31862047\n",
      "Iteration 23, loss = 0.31291162\n",
      "Iteration 24, loss = 0.30774148\n",
      "Iteration 25, loss = 0.30306472\n",
      "Iteration 26, loss = 0.29889858\n",
      "Iteration 27, loss = 0.29907585\n",
      "Iteration 28, loss = 0.29221205\n",
      "Iteration 29, loss = 0.29134665\n",
      "Iteration 30, loss = 0.28367399\n",
      "Iteration 31, loss = 0.28338990\n",
      "Iteration 32, loss = 0.27945154\n",
      "Iteration 33, loss = 0.27568381\n",
      "Iteration 34, loss = 0.27369384\n",
      "Iteration 35, loss = 0.27316035\n",
      "Iteration 36, loss = 0.26868292\n",
      "Iteration 37, loss = 0.26951458\n",
      "Iteration 38, loss = 0.26884382\n",
      "Iteration 39, loss = 0.26477837\n",
      "Iteration 40, loss = 0.26390584\n",
      "Iteration 41, loss = 0.26328920\n",
      "Iteration 42, loss = 0.25665190\n",
      "Iteration 43, loss = 0.25636954\n",
      "Iteration 44, loss = 0.25793103\n",
      "Iteration 45, loss = 0.25406900\n",
      "Iteration 46, loss = 0.25082722\n",
      "Iteration 47, loss = 0.25042717\n",
      "Iteration 48, loss = 0.24741104\n",
      "Iteration 49, loss = 0.24517782\n",
      "Iteration 50, loss = 0.24698322\n",
      "Iteration 51, loss = 0.24817245\n",
      "Iteration 52, loss = 0.24212615\n",
      "Iteration 53, loss = 0.24227521\n",
      "Iteration 54, loss = 0.24112914\n",
      "Iteration 55, loss = 0.24054408\n",
      "Iteration 56, loss = 0.23904675\n",
      "Iteration 57, loss = 0.24039119\n",
      "Iteration 58, loss = 0.23630736\n",
      "Iteration 59, loss = 0.23379686\n",
      "Iteration 60, loss = 0.23568536\n",
      "Iteration 61, loss = 0.23493197\n",
      "Iteration 62, loss = 0.23057676\n",
      "Iteration 63, loss = 0.23483026\n",
      "Iteration 64, loss = 0.23055337\n",
      "Iteration 65, loss = 0.22659592\n",
      "Iteration 66, loss = 0.23084601\n",
      "Iteration 67, loss = 0.23178164\n",
      "Iteration 68, loss = 0.22771201\n",
      "Iteration 69, loss = 0.22362230\n",
      "Iteration 70, loss = 0.22488884\n",
      "Iteration 71, loss = 0.22759179\n",
      "Iteration 72, loss = 0.22413163\n",
      "Iteration 73, loss = 0.22204480\n",
      "Iteration 74, loss = 0.22406566\n",
      "Iteration 75, loss = 0.22443238\n",
      "Iteration 76, loss = 0.22720337\n",
      "Iteration 77, loss = 0.22765386\n",
      "Iteration 78, loss = 0.22936443\n",
      "Iteration 79, loss = 0.22251914\n",
      "Iteration 80, loss = 0.21997669\n",
      "Iteration 81, loss = 0.22545443\n",
      "Iteration 82, loss = 0.21952892\n",
      "Iteration 83, loss = 0.21891965\n",
      "Iteration 84, loss = 0.21896290\n",
      "Iteration 85, loss = 0.22094398\n",
      "Iteration 86, loss = 0.21922572\n",
      "Iteration 87, loss = 0.21886407\n",
      "Iteration 88, loss = 0.22306165\n",
      "Iteration 89, loss = 0.22120169\n",
      "Iteration 90, loss = 0.21934438\n",
      "Iteration 91, loss = 0.21740124\n",
      "Iteration 92, loss = 0.21900337\n",
      "Iteration 93, loss = 0.21585395\n",
      "Iteration 94, loss = 0.21482520\n",
      "Iteration 95, loss = 0.21489782\n",
      "Iteration 96, loss = 0.21839944\n",
      "Iteration 97, loss = 0.21448375\n",
      "Iteration 98, loss = 0.21606947\n",
      "Iteration 99, loss = 0.21710183\n",
      "Iteration 100, loss = 0.21343761\n",
      "Iteration 1, loss = 1.36895774\n",
      "Iteration 2, loss = 1.17453882\n",
      "Iteration 3, loss = 1.01133616\n",
      "Iteration 4, loss = 0.87880990\n",
      "Iteration 5, loss = 0.76543171\n",
      "Iteration 6, loss = 0.67237229\n",
      "Iteration 7, loss = 0.59194974\n",
      "Iteration 8, loss = 0.52607659\n",
      "Iteration 9, loss = 0.47040700\n",
      "Iteration 10, loss = 0.42833116\n",
      "Iteration 11, loss = 0.39693940\n",
      "Iteration 12, loss = 0.37140695\n",
      "Iteration 13, loss = 0.35834875\n",
      "Iteration 14, loss = 0.34042087\n",
      "Iteration 15, loss = 0.33101441\n",
      "Iteration 16, loss = 0.32085059\n",
      "Iteration 17, loss = 0.31439030\n",
      "Iteration 18, loss = 0.30698475\n",
      "Iteration 19, loss = 0.30309559\n",
      "Iteration 20, loss = 0.29889840\n",
      "Iteration 21, loss = 0.29300324\n",
      "Iteration 22, loss = 0.28844587\n",
      "Iteration 23, loss = 0.28486875\n",
      "Iteration 24, loss = 0.28239037\n",
      "Iteration 25, loss = 0.27846314\n",
      "Iteration 26, loss = 0.27731204\n",
      "Iteration 27, loss = 0.27800734\n",
      "Iteration 28, loss = 0.27237210\n",
      "Iteration 29, loss = 0.27247245\n",
      "Iteration 30, loss = 0.26748612\n",
      "Iteration 31, loss = 0.26476522\n",
      "Iteration 32, loss = 0.26897651\n",
      "Iteration 33, loss = 0.26265605\n",
      "Iteration 34, loss = 0.26258983\n",
      "Iteration 35, loss = 0.26073364\n",
      "Iteration 36, loss = 0.25962077\n",
      "Iteration 37, loss = 0.25667964\n",
      "Iteration 38, loss = 0.25613093\n",
      "Iteration 39, loss = 0.25796601\n",
      "Iteration 40, loss = 0.25362518\n",
      "Iteration 41, loss = 0.25249152\n",
      "Iteration 42, loss = 0.25477161\n",
      "Iteration 43, loss = 0.25267974\n",
      "Iteration 44, loss = 0.25066848\n",
      "Iteration 45, loss = 0.25176361\n",
      "Iteration 46, loss = 0.25072380\n",
      "Iteration 47, loss = 0.24800138\n",
      "Iteration 48, loss = 0.24886254\n",
      "Iteration 49, loss = 0.24820585\n",
      "Iteration 50, loss = 0.24687162\n",
      "Iteration 51, loss = 0.24473637\n",
      "Iteration 52, loss = 0.24614996\n",
      "Iteration 53, loss = 0.24573085\n",
      "Iteration 54, loss = 0.24363705\n",
      "Iteration 55, loss = 0.24451573\n",
      "Iteration 56, loss = 0.24411055\n",
      "Iteration 57, loss = 0.24209638\n",
      "Iteration 58, loss = 0.24291951\n",
      "Iteration 59, loss = 0.24382278\n",
      "Iteration 60, loss = 0.24439242\n",
      "Iteration 61, loss = 0.24605954\n",
      "Iteration 62, loss = 0.24361390\n",
      "Iteration 63, loss = 0.24024611\n",
      "Iteration 64, loss = 0.24380771\n",
      "Iteration 65, loss = 0.23925052\n",
      "Iteration 66, loss = 0.24069786\n",
      "Iteration 67, loss = 0.23917369\n",
      "Iteration 68, loss = 0.24082033\n",
      "Iteration 69, loss = 0.24415310\n",
      "Iteration 70, loss = 0.23877188\n",
      "Iteration 71, loss = 0.24183181\n",
      "Iteration 72, loss = 0.23792704\n",
      "Iteration 73, loss = 0.23763435\n",
      "Iteration 74, loss = 0.24567392\n",
      "Iteration 75, loss = 0.23783534\n",
      "Iteration 76, loss = 0.23656299\n",
      "Iteration 77, loss = 0.23580066\n",
      "Iteration 78, loss = 0.23468104\n",
      "Iteration 79, loss = 0.23812570\n",
      "Iteration 80, loss = 0.23695839\n",
      "Iteration 81, loss = 0.23523917\n",
      "Iteration 82, loss = 0.23507414\n",
      "Iteration 83, loss = 0.23770623\n",
      "Iteration 84, loss = 0.23214458\n",
      "Iteration 85, loss = 0.23441644\n",
      "Iteration 86, loss = 0.23284187\n",
      "Iteration 87, loss = 0.23912172\n",
      "Iteration 88, loss = 0.23329366\n",
      "Iteration 89, loss = 0.23404124\n",
      "Iteration 90, loss = 0.23154128\n",
      "Iteration 91, loss = 0.23249986\n",
      "Iteration 92, loss = 0.23310246\n",
      "Iteration 93, loss = 0.23630424\n",
      "Iteration 94, loss = 0.23413965\n",
      "Iteration 95, loss = 0.23852518\n",
      "Iteration 96, loss = 0.23732006\n",
      "Iteration 97, loss = 0.23364345\n",
      "Iteration 98, loss = 0.23775566\n",
      "Iteration 99, loss = 0.23328411\n",
      "Iteration 100, loss = 0.23348951\n",
      "Iteration 1, loss = 1.41516965\n",
      "Iteration 2, loss = 1.23851581\n",
      "Iteration 3, loss = 1.09292968\n",
      "Iteration 4, loss = 0.95918549\n",
      "Iteration 5, loss = 0.83909565\n",
      "Iteration 6, loss = 0.73521501\n",
      "Iteration 7, loss = 0.65296469\n",
      "Iteration 8, loss = 0.58222641\n",
      "Iteration 9, loss = 0.52133988\n",
      "Iteration 10, loss = 0.46945877\n",
      "Iteration 11, loss = 0.42013036\n",
      "Iteration 12, loss = 0.38647879\n",
      "Iteration 13, loss = 0.34719183\n",
      "Iteration 14, loss = 0.32933436\n",
      "Iteration 15, loss = 0.30843495\n",
      "Iteration 16, loss = 0.29875888\n",
      "Iteration 17, loss = 0.28678751\n",
      "Iteration 18, loss = 0.27225999\n",
      "Iteration 19, loss = 0.26589727\n",
      "Iteration 20, loss = 0.26340073\n",
      "Iteration 21, loss = 0.25702763\n",
      "Iteration 22, loss = 0.25650937\n",
      "Iteration 23, loss = 0.25214376\n",
      "Iteration 24, loss = 0.25010277\n",
      "Iteration 25, loss = 0.23921214\n",
      "Iteration 26, loss = 0.24480059\n",
      "Iteration 27, loss = 0.23734204\n",
      "Iteration 28, loss = 0.23822703\n",
      "Iteration 29, loss = 0.24226161\n",
      "Iteration 30, loss = 0.23353627\n",
      "Iteration 31, loss = 0.23220340\n",
      "Iteration 32, loss = 0.23266617\n",
      "Iteration 33, loss = 0.22952108\n",
      "Iteration 34, loss = 0.22840467\n",
      "Iteration 35, loss = 0.22671362\n",
      "Iteration 36, loss = 0.22520958\n",
      "Iteration 37, loss = 0.22315555\n",
      "Iteration 38, loss = 0.22542709\n",
      "Iteration 39, loss = 0.22280558\n",
      "Iteration 40, loss = 0.22538009\n",
      "Iteration 41, loss = 0.21851765\n",
      "Iteration 42, loss = 0.22243025\n",
      "Iteration 43, loss = 0.21968655\n",
      "Iteration 44, loss = 0.22108323\n",
      "Iteration 45, loss = 0.22355022\n",
      "Iteration 46, loss = 0.21890796\n",
      "Iteration 47, loss = 0.21703601\n",
      "Iteration 48, loss = 0.21568844\n",
      "Iteration 49, loss = 0.21550661\n",
      "Iteration 50, loss = 0.21361300\n",
      "Iteration 51, loss = 0.21572373\n",
      "Iteration 52, loss = 0.21631607\n",
      "Iteration 53, loss = 0.21864966\n",
      "Iteration 54, loss = 0.21349970\n",
      "Iteration 55, loss = 0.21553230\n",
      "Iteration 56, loss = 0.21349139\n",
      "Iteration 57, loss = 0.21376955\n",
      "Iteration 58, loss = 0.21643717\n",
      "Iteration 59, loss = 0.21077690\n",
      "Iteration 60, loss = 0.21271505\n",
      "Iteration 61, loss = 0.21330915\n",
      "Iteration 62, loss = 0.21225250\n",
      "Iteration 63, loss = 0.21324502\n",
      "Iteration 64, loss = 0.21631637\n",
      "Iteration 65, loss = 0.21377622\n",
      "Iteration 66, loss = 0.21100309\n",
      "Iteration 67, loss = 0.21368900\n",
      "Iteration 68, loss = 0.21148742\n",
      "Iteration 69, loss = 0.21127496\n",
      "Iteration 70, loss = 0.21030735\n",
      "Iteration 71, loss = 0.20981846\n",
      "Iteration 72, loss = 0.21209076\n",
      "Iteration 73, loss = 0.20998541\n",
      "Iteration 74, loss = 0.20805726\n",
      "Iteration 75, loss = 0.20874406\n",
      "Iteration 76, loss = 0.20898159\n",
      "Iteration 77, loss = 0.20741426\n",
      "Iteration 78, loss = 0.20754443\n",
      "Iteration 79, loss = 0.21022113\n",
      "Iteration 80, loss = 0.21190988\n",
      "Iteration 81, loss = 0.21155031\n",
      "Iteration 82, loss = 0.21193876\n",
      "Iteration 83, loss = 0.21363704\n",
      "Iteration 84, loss = 0.20923066\n",
      "Iteration 85, loss = 0.20696042\n",
      "Iteration 86, loss = 0.20782798\n",
      "Iteration 87, loss = 0.21281306\n",
      "Iteration 88, loss = 0.20660879\n",
      "Iteration 89, loss = 0.20945907\n",
      "Iteration 90, loss = 0.20499839\n",
      "Iteration 91, loss = 0.20373460\n",
      "Iteration 92, loss = 0.20727069\n",
      "Iteration 93, loss = 0.20954350\n",
      "Iteration 94, loss = 0.20772317\n",
      "Iteration 95, loss = 0.20643945\n",
      "Iteration 96, loss = 0.20679241\n",
      "Iteration 97, loss = 0.20498588\n",
      "Iteration 98, loss = 0.20782917\n",
      "Iteration 99, loss = 0.20771652\n",
      "Iteration 100, loss = 0.20782327\n",
      "Train Accuracy: 92.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 88.0%\n",
      "Train Accuracy: 88.0%\n",
      "INPUT:  [[1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[{'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.267, 0.55 , 0.075, 0.109]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.262, 0.283, 0.205, 0.25 ]), 'nn': array([0.213, 0.627, 0.069, 0.092]), 'svc': array([0.361, 0.531, 0.024, 0.085]), 'nb': array([0.232, 0.759, 0.001, 0.008])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.288, 0.352, 0.277]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.091, 0.351, 0.19 , 0.368]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.456, 0.09 , 0.366, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.35 , 0.094, 0.453, 0.102]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.105, 0.084, 0.155, 0.657]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.085, 0.091, 0.076, 0.747]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.674, 0.138, 0.079, 0.109]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.089, 0.101, 0.61 , 0.2  ]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.225, 0.239, 0.264, 0.272]), 'nn': array([0.079, 0.088, 0.741, 0.092]), 'svc': array([0.043, 0.031, 0.626, 0.3  ]), 'nb': array([0.01 , 0.045, 0.809, 0.136])}}, {'ensemble_proba': array([0.11, 0.51, 0.08, 0.3 ]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.232, 0.278, 0.218, 0.272]), 'nn': array([0.094, 0.367, 0.078, 0.462]), 'svc': array([0.093, 0.592, 0.023, 0.293]), 'nb': array([0.02 , 0.802, 0.002, 0.175])}}, {'ensemble_proba': array([0.083, 0.288, 0.352, 0.277]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.091, 0.351, 0.19 , 0.368]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.434, 0.23 , 0.094, 0.242]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.501, 0.105, 0.078, 0.316]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.456, 0.09 , 0.366, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.35 , 0.094, 0.453, 0.102]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.199, 0.594, 0.094, 0.113]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.267, 0.234, 0.251]), 'nn': array([0.095, 0.726, 0.072, 0.107]), 'svc': array([0.281, 0.603, 0.047, 0.069]), 'nb': array([0.17 , 0.779, 0.024, 0.027])}}, {'ensemble_proba': array([0.456, 0.09 , 0.366, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.35 , 0.094, 0.453, 0.102]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.215, 0.081, 0.56 , 0.145]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.259, 0.217, 0.258, 0.267]), 'nn': array([0.112, 0.087, 0.709, 0.092]), 'svc': array([0.245, 0.011, 0.609, 0.135]), 'nb': array([0.243, 0.007, 0.665, 0.085])}}, {'ensemble_proba': array([0.456, 0.09 , 0.366, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.35 , 0.094, 0.453, 0.102]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.168, 0.643, 0.094, 0.095]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.089, 0.751, 0.069, 0.091]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.168, 0.643, 0.094, 0.095]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.089, 0.751, 0.069, 0.091]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.168, 0.643, 0.094, 0.095]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.089, 0.751, 0.069, 0.091]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.674, 0.138, 0.079, 0.109]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.456, 0.09 , 0.366, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.35 , 0.094, 0.453, 0.102]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.082, 0.14 , 0.096, 0.683]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.213, 0.248, 0.218, 0.32 ]), 'nn': array([0.083, 0.096, 0.073, 0.748]), 'svc': array([0.031, 0.193, 0.089, 0.687]), 'nb': array([0.001, 0.021, 0.003, 0.976])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.078, 0.763, 0.068, 0.091]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.667, 0.137, 0.112, 0.084]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.297, 0.244, 0.244, 0.215]), 'nn': array([0.748, 0.091, 0.069, 0.092]), 'svc': array([0.661, 0.195, 0.117, 0.027]), 'nb': array([0.962, 0.018, 0.02 , 0.   ])}}, {'ensemble_proba': array([0.09 , 0.123, 0.635, 0.153]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.232, 0.238, 0.273, 0.258]), 'nn': array([0.094, 0.089, 0.639, 0.178]), 'svc': array([0.03 , 0.156, 0.683, 0.131]), 'nb': array([0.004, 0.01 , 0.943, 0.043])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.078, 0.763, 0.068, 0.091]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.183, 0.097, 0.084, 0.636]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.244, 0.236, 0.225, 0.295]), 'nn': array([0.092, 0.091, 0.074, 0.743]), 'svc': array([0.296, 0.046, 0.026, 0.632]), 'nb': array([0.1  , 0.014, 0.011, 0.875])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.434, 0.23 , 0.094, 0.242]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.501, 0.105, 0.078, 0.316]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.124, 0.121, 0.167, 0.588]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.105, 0.189, 0.197, 0.509]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.626, 0.101, 0.09 , 0.182]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.27 , 0.238, 0.223, 0.269]), 'nn': array([0.743, 0.096, 0.069, 0.092]), 'svc': array([0.625, 0.025, 0.05 , 0.3  ]), 'nb': array([0.868, 0.046, 0.02 , 0.066])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.078, 0.763, 0.068, 0.091]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.105, 0.084, 0.155, 0.657]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.085, 0.091, 0.076, 0.747]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.397, 0.309, 0.206, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.262, 0.255, 0.256, 0.227]), 'nn': array([0.573, 0.25 , 0.084, 0.093]), 'svc': array([0.368, 0.416, 0.19 , 0.026]), 'nb': array([0.387, 0.316, 0.294, 0.003])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.106, 0.075, 0.649, 0.169]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.246, 0.205, 0.284, 0.265]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.085, 0.01 , 0.608, 0.296]), 'nb': array([0.013, 0.   , 0.96 , 0.027])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.078, 0.763, 0.068, 0.091]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.157, 0.085, 0.677, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.269, 0.209, 0.312, 0.21 ]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.271, 0.044, 0.657, 0.027]), 'nb': array([0.007, 0.   , 0.993, 0.   ])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.584, 0.087, 0.099, 0.23 ]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.272, 0.224, 0.227, 0.277]), 'nn': array([0.7  , 0.096, 0.078, 0.126]), 'svc': array([0.555, 0.016, 0.068, 0.361]), 'nb': array([0.808, 0.012, 0.023, 0.157])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.431, 0.137, 0.076, 0.357]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.248, 0.203, 0.295]), 'nn': array([0.607, 0.103, 0.074, 0.216]), 'svc': array([0.508, 0.09 , 0.024, 0.378]), 'nb': array([0.355, 0.106, 0.001, 0.538])}}, {'ensemble_proba': array([0.084, 0.157, 0.648, 0.111]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.08 , 0.098, 0.728, 0.095]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.089, 0.101, 0.61 , 0.2  ]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.225, 0.239, 0.264, 0.272]), 'nn': array([0.079, 0.088, 0.741, 0.092]), 'svc': array([0.043, 0.031, 0.626, 0.3  ]), 'nb': array([0.01 , 0.045, 0.809, 0.136])}}, {'ensemble_proba': array([0.124, 0.121, 0.167, 0.588]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.105, 0.189, 0.197, 0.509]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.124, 0.121, 0.167, 0.588]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.105, 0.189, 0.197, 0.509]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.084, 0.157, 0.648, 0.111]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.08 , 0.098, 0.728, 0.095]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.078, 0.763, 0.068, 0.091]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.078, 0.763, 0.068, 0.091]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.434, 0.23 , 0.094, 0.242]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.501, 0.105, 0.078, 0.316]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.654, 0.075, 0.114, 0.156]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.295, 0.204, 0.24 , 0.261]), 'nn': array([0.747, 0.085, 0.077, 0.092]), 'svc': array([0.608, 0.011, 0.121, 0.26 ]), 'nb': array([0.968, 0.   , 0.02 , 0.011])}}, {'ensemble_proba': array([0.156, 0.085, 0.677, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.269, 0.209, 0.312, 0.21 ]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.271, 0.044, 0.657, 0.027]), 'nb': array([0.007, 0.   , 0.993, 0.   ])}}, {'ensemble_proba': array([0.173, 0.463, 0.131, 0.234]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.252, 0.244, 0.255]), 'nn': array([0.156, 0.598, 0.086, 0.159]), 'svc': array([0.082, 0.591, 0.037, 0.291]), 'nb': array([0.205, 0.41 , 0.155, 0.23 ])}}, {'ensemble_proba': array([0.674, 0.084, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.084, 0.169, 0.091, 0.656]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.211, 0.263, 0.214, 0.313]), 'nn': array([0.084, 0.099, 0.073, 0.744]), 'svc': array([0.041, 0.223, 0.075, 0.662]), 'nb': array([0.001, 0.091, 0.003, 0.905])}}, {'ensemble_proba': array([0.124, 0.121, 0.167, 0.588]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.105, 0.189, 0.197, 0.509]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.082, 0.14 , 0.096, 0.683]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.213, 0.248, 0.218, 0.32 ]), 'nn': array([0.083, 0.096, 0.073, 0.748]), 'svc': array([0.031, 0.193, 0.089, 0.687]), 'nb': array([0.001, 0.021, 0.003, 0.976])}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 0, 3, 2, 0, 3, 0, 2, 1, 2, 0, 0, 2, 3, 1, 0, 0, 2, 0, 1,\n",
       "       2, 3, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 0, 0, 2, 0, 1, 3, 1, 0, 2,\n",
       "       3, 1, 3, 1, 0, 3, 0, 1, 0, 3, 3, 3, 0, 0, 0, 2, 1, 2, 1, 1, 2, 0,\n",
       "       0, 0, 0, 2, 1, 3, 2, 2, 3, 3, 1, 3, 2, 1, 3, 1, 1, 0, 3, 3, 0, 2,\n",
       "       1, 0, 1, 3, 3, 2, 1, 3, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Classifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26307ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  [[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[{'ensemble_proba': array([0.456, 0.09 , 0.366, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.35 , 0.094, 0.453, 0.102]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.123, 0.128, 0.665, 0.084]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.248, 0.245, 0.289, 0.217]), 'nn': array([0.089, 0.089, 0.732, 0.091]), 'svc': array([0.143, 0.156, 0.674, 0.027]), 'nb': array([0.013, 0.021, 0.965, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.084, 0.157, 0.648, 0.111]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.08 , 0.098, 0.728, 0.095]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.434, 0.23 , 0.094, 0.242]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.501, 0.105, 0.078, 0.316]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.16 , 0.085, 0.674, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.31 , 0.211]), 'nn': array([0.079, 0.086, 0.746, 0.09 ]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.173, 0.463, 0.131, 0.234]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.252, 0.244, 0.255]), 'nn': array([0.156, 0.598, 0.086, 0.159]), 'svc': array([0.082, 0.591, 0.037, 0.291]), 'nb': array([0.205, 0.41 , 0.155, 0.23 ])}}, {'ensemble_proba': array([0.674, 0.138, 0.079, 0.109]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.756, 0.085, 0.068, 0.091]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.078, 0.763, 0.068, 0.091]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.288, 0.352, 0.277]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.091, 0.351, 0.19 , 0.368]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.081, 0.114, 0.241, 0.564]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.203, 0.24 , 0.248, 0.309]), 'nn': array([0.093, 0.154, 0.263, 0.49 ]), 'svc': array([0.026, 0.045, 0.326, 0.602]), 'nb': array([0.   , 0.02 , 0.127, 0.853])}}, {'ensemble_proba': array([0.105, 0.084, 0.155, 0.657]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.085, 0.091, 0.076, 0.747]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.626, 0.101, 0.09 , 0.182]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.27 , 0.238, 0.223, 0.269]), 'nn': array([0.743, 0.096, 0.069, 0.092]), 'svc': array([0.625, 0.025, 0.05 , 0.3  ]), 'nb': array([0.868, 0.046, 0.02 , 0.066])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.078, 0.763, 0.068, 0.091]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.456, 0.09 , 0.366, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.35 , 0.094, 0.453, 0.102]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.124, 0.121, 0.167, 0.588]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.105, 0.189, 0.197, 0.509]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.083, 0.288, 0.352, 0.277]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.091, 0.351, 0.19 , 0.368]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.084, 0.28 , 0.078, 0.559]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.196, 0.287, 0.19 , 0.327]), 'nn': array([0.089, 0.245, 0.078, 0.589]), 'svc': array([0.051, 0.255, 0.043, 0.651]), 'nb': array([0.   , 0.333, 0.   , 0.667])}}, {'ensemble_proba': array([0.083, 0.164, 0.077, 0.676]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.083, 0.092, 0.072, 0.753]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.093, 0.576, 0.073, 0.258]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.081, 0.686, 0.071, 0.163]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}]\n",
      "Test Accuracy: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "accuracy = np.mean(np.array(preds) == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea208645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  [[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[{'ensemble_proba': array([0.456, 0.09 , 0.366, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.35 , 0.094, 0.453, 0.102]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pacman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
