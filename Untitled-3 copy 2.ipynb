{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7670f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.48559747\n",
      "Iteration 2, loss = 1.36635309\n",
      "Iteration 3, loss = 1.27113625\n",
      "Iteration 4, loss = 1.16804603\n",
      "Iteration 5, loss = 1.05176353\n",
      "Iteration 6, loss = 0.95663514\n",
      "Iteration 7, loss = 0.84009199\n",
      "Iteration 8, loss = 0.74258620\n",
      "Iteration 9, loss = 0.65417869\n",
      "Iteration 10, loss = 0.58020486\n",
      "Iteration 11, loss = 0.51164692\n",
      "Iteration 12, loss = 0.45223292\n",
      "Iteration 13, loss = 0.39742806\n",
      "Iteration 14, loss = 0.35265596\n",
      "Iteration 15, loss = 0.32234215\n",
      "Iteration 16, loss = 0.30051809\n",
      "Iteration 17, loss = 0.28390005\n",
      "Iteration 18, loss = 0.27377830\n",
      "Iteration 19, loss = 0.26609642\n",
      "Iteration 20, loss = 0.25740949\n",
      "Iteration 21, loss = 0.25609662\n",
      "Iteration 22, loss = 0.25053475\n",
      "Iteration 23, loss = 0.24564725\n",
      "Iteration 24, loss = 0.24194330\n",
      "Iteration 25, loss = 0.24114125\n",
      "Iteration 26, loss = 0.24017952\n",
      "Iteration 27, loss = 0.23778953\n",
      "Iteration 28, loss = 0.23392938\n",
      "Iteration 29, loss = 0.23482510\n",
      "Iteration 30, loss = 0.23225971\n",
      "Iteration 31, loss = 0.23256382\n",
      "Iteration 32, loss = 0.23500829\n",
      "Iteration 33, loss = 0.23904339\n",
      "Iteration 34, loss = 0.22745335\n",
      "Iteration 35, loss = 0.22998720\n",
      "Iteration 36, loss = 0.22632148\n",
      "Iteration 37, loss = 0.22418895\n",
      "Iteration 38, loss = 0.22334478\n",
      "Iteration 39, loss = 0.22474605\n",
      "Iteration 40, loss = 0.22215499\n",
      "Iteration 41, loss = 0.22448681\n",
      "Iteration 42, loss = 0.22163728\n",
      "Iteration 43, loss = 0.21963993\n",
      "Iteration 44, loss = 0.22267672\n",
      "Iteration 45, loss = 0.22195162\n",
      "Iteration 46, loss = 0.22159585\n",
      "Iteration 47, loss = 0.21877276\n",
      "Iteration 48, loss = 0.21553448\n",
      "Iteration 49, loss = 0.22130593\n",
      "Iteration 50, loss = 0.22273034\n",
      "Iteration 51, loss = 0.21520667\n",
      "Iteration 52, loss = 0.21614720\n",
      "Iteration 53, loss = 0.21638231\n",
      "Iteration 54, loss = 0.21449063\n",
      "Iteration 55, loss = 0.21628519\n",
      "Iteration 56, loss = 0.21359873\n",
      "Iteration 57, loss = 0.21336839\n",
      "Iteration 58, loss = 0.21334592\n",
      "Iteration 59, loss = 0.21240850\n",
      "Iteration 60, loss = 0.21271061\n",
      "Iteration 61, loss = 0.21289070\n",
      "Iteration 62, loss = 0.21109747\n",
      "Iteration 63, loss = 0.21483935\n",
      "Iteration 64, loss = 0.20936876\n",
      "Iteration 65, loss = 0.21957700\n",
      "Iteration 66, loss = 0.21660513\n",
      "Iteration 67, loss = 0.21209419\n",
      "Iteration 68, loss = 0.21276656\n",
      "Iteration 69, loss = 0.21246379\n",
      "Iteration 70, loss = 0.21164936\n",
      "Iteration 71, loss = 0.20916982\n",
      "Iteration 72, loss = 0.21523848\n",
      "Iteration 73, loss = 0.21750994\n",
      "Iteration 74, loss = 0.21002213\n",
      "Iteration 75, loss = 0.21083463\n",
      "Iteration 76, loss = 0.21390238\n",
      "Iteration 77, loss = 0.21062570\n",
      "Iteration 78, loss = 0.20786531\n",
      "Iteration 79, loss = 0.20874768\n",
      "Iteration 80, loss = 0.20699014\n",
      "Iteration 81, loss = 0.20743012\n",
      "Iteration 82, loss = 0.20772879\n",
      "Iteration 83, loss = 0.20596251\n",
      "Iteration 84, loss = 0.20766581\n",
      "Iteration 85, loss = 0.20823015\n",
      "Iteration 86, loss = 0.20664644\n",
      "Iteration 87, loss = 0.20707312\n",
      "Iteration 88, loss = 0.21064326\n",
      "Iteration 89, loss = 0.21046962\n",
      "Iteration 90, loss = 0.20762577\n",
      "Iteration 91, loss = 0.20628553\n",
      "Iteration 92, loss = 0.20349219\n",
      "Iteration 93, loss = 0.20616626\n",
      "Iteration 94, loss = 0.20518606\n",
      "Iteration 95, loss = 0.20860857\n",
      "Iteration 96, loss = 0.20631031\n",
      "Iteration 97, loss = 0.20410335\n",
      "Iteration 98, loss = 0.20504820\n",
      "Iteration 99, loss = 0.20808176\n",
      "Iteration 100, loss = 0.20583198\n",
      "Iteration 1, loss = 1.42460198\n",
      "Iteration 2, loss = 1.22149183\n",
      "Iteration 3, loss = 1.07268132\n",
      "Iteration 4, loss = 0.95935793\n",
      "Iteration 5, loss = 0.86664437\n",
      "Iteration 6, loss = 0.78942521\n",
      "Iteration 7, loss = 0.72867090\n",
      "Iteration 8, loss = 0.67830034\n",
      "Iteration 9, loss = 0.63236796\n",
      "Iteration 10, loss = 0.58560084\n",
      "Iteration 11, loss = 0.54143338\n",
      "Iteration 12, loss = 0.49912131\n",
      "Iteration 13, loss = 0.46791795\n",
      "Iteration 14, loss = 0.43252140\n",
      "Iteration 15, loss = 0.40919144\n",
      "Iteration 16, loss = 0.38793379\n",
      "Iteration 17, loss = 0.37663573\n",
      "Iteration 18, loss = 0.36034459\n",
      "Iteration 19, loss = 0.35511879\n",
      "Iteration 20, loss = 0.34287104\n",
      "Iteration 21, loss = 0.33967320\n",
      "Iteration 22, loss = 0.33101516\n",
      "Iteration 23, loss = 0.32539794\n",
      "Iteration 24, loss = 0.32470860\n",
      "Iteration 25, loss = 0.31542541\n",
      "Iteration 26, loss = 0.31513886\n",
      "Iteration 27, loss = 0.30790608\n",
      "Iteration 28, loss = 0.30839147\n",
      "Iteration 29, loss = 0.30309709\n",
      "Iteration 30, loss = 0.30161789\n",
      "Iteration 31, loss = 0.30594594\n",
      "Iteration 32, loss = 0.29903676\n",
      "Iteration 33, loss = 0.29410887\n",
      "Iteration 34, loss = 0.29115809\n",
      "Iteration 35, loss = 0.29030248\n",
      "Iteration 36, loss = 0.28805285\n",
      "Iteration 37, loss = 0.28653163\n",
      "Iteration 38, loss = 0.28459499\n",
      "Iteration 39, loss = 0.28030716\n",
      "Iteration 40, loss = 0.28318879\n",
      "Iteration 41, loss = 0.28202579\n",
      "Iteration 42, loss = 0.27679220\n",
      "Iteration 43, loss = 0.27464346\n",
      "Iteration 44, loss = 0.27390459\n",
      "Iteration 45, loss = 0.27342585\n",
      "Iteration 46, loss = 0.27062050\n",
      "Iteration 47, loss = 0.26700187\n",
      "Iteration 48, loss = 0.26855140\n",
      "Iteration 49, loss = 0.27052864\n",
      "Iteration 50, loss = 0.26845042\n",
      "Iteration 51, loss = 0.26470890\n",
      "Iteration 52, loss = 0.26549218\n",
      "Iteration 53, loss = 0.26319095\n",
      "Iteration 54, loss = 0.26806701\n",
      "Iteration 55, loss = 0.26306485\n",
      "Iteration 56, loss = 0.26302472\n",
      "Iteration 57, loss = 0.25859545\n",
      "Iteration 58, loss = 0.26639657\n",
      "Iteration 59, loss = 0.25693826\n",
      "Iteration 60, loss = 0.25641321\n",
      "Iteration 61, loss = 0.25866500\n",
      "Iteration 62, loss = 0.25697655\n",
      "Iteration 63, loss = 0.25414593\n",
      "Iteration 64, loss = 0.26475534\n",
      "Iteration 65, loss = 0.25196707\n",
      "Iteration 66, loss = 0.25947418\n",
      "Iteration 67, loss = 0.25415065\n",
      "Iteration 68, loss = 0.25212982\n",
      "Iteration 69, loss = 0.25441735\n",
      "Iteration 70, loss = 0.25478559\n",
      "Iteration 71, loss = 0.24932607\n",
      "Iteration 72, loss = 0.25016125\n",
      "Iteration 73, loss = 0.24879174\n",
      "Iteration 74, loss = 0.24854501\n",
      "Iteration 75, loss = 0.24985944\n",
      "Iteration 76, loss = 0.25402585\n",
      "Iteration 77, loss = 0.25157787\n",
      "Iteration 78, loss = 0.24653672\n",
      "Iteration 79, loss = 0.25343194\n",
      "Iteration 80, loss = 0.25127232\n",
      "Iteration 81, loss = 0.24537072\n",
      "Iteration 82, loss = 0.24571485\n",
      "Iteration 83, loss = 0.24604063\n",
      "Iteration 84, loss = 0.24240914\n",
      "Iteration 85, loss = 0.24475070\n",
      "Iteration 86, loss = 0.24620359\n",
      "Iteration 87, loss = 0.24310057\n",
      "Iteration 88, loss = 0.24134662\n",
      "Iteration 89, loss = 0.24669421\n",
      "Iteration 90, loss = 0.24720125\n",
      "Iteration 91, loss = 0.24901670\n",
      "Iteration 92, loss = 0.24329055\n",
      "Iteration 93, loss = 0.24231954\n",
      "Iteration 94, loss = 0.24026538\n",
      "Iteration 95, loss = 0.24285958\n",
      "Iteration 96, loss = 0.24308095\n",
      "Iteration 97, loss = 0.23881861\n",
      "Iteration 98, loss = 0.24173438\n",
      "Iteration 99, loss = 0.24203625\n",
      "Iteration 100, loss = 0.23965030\n",
      "Iteration 1, loss = 1.48482512\n",
      "Iteration 2, loss = 1.35265696\n",
      "Iteration 3, loss = 1.23854999\n",
      "Iteration 4, loss = 1.14055263\n",
      "Iteration 5, loss = 1.04539712\n",
      "Iteration 6, loss = 0.95304563\n",
      "Iteration 7, loss = 0.86424190\n",
      "Iteration 8, loss = 0.74885790\n",
      "Iteration 9, loss = 0.65596217\n",
      "Iteration 10, loss = 0.56852699\n",
      "Iteration 11, loss = 0.50335921\n",
      "Iteration 12, loss = 0.44809269\n",
      "Iteration 13, loss = 0.41293813\n",
      "Iteration 14, loss = 0.38372886\n",
      "Iteration 15, loss = 0.36311856\n",
      "Iteration 16, loss = 0.34479555\n",
      "Iteration 17, loss = 0.33634956\n",
      "Iteration 18, loss = 0.32145596\n",
      "Iteration 19, loss = 0.31608634\n",
      "Iteration 20, loss = 0.30825958\n",
      "Iteration 21, loss = 0.30081361\n",
      "Iteration 22, loss = 0.29580380\n",
      "Iteration 23, loss = 0.29143774\n",
      "Iteration 24, loss = 0.28921153\n",
      "Iteration 25, loss = 0.28535170\n",
      "Iteration 26, loss = 0.28116821\n",
      "Iteration 27, loss = 0.27970417\n",
      "Iteration 28, loss = 0.27583562\n",
      "Iteration 29, loss = 0.27273312\n",
      "Iteration 30, loss = 0.27635968\n",
      "Iteration 31, loss = 0.26993203\n",
      "Iteration 32, loss = 0.26923582\n",
      "Iteration 33, loss = 0.26603521\n",
      "Iteration 34, loss = 0.26399008\n",
      "Iteration 35, loss = 0.26366971\n",
      "Iteration 36, loss = 0.26096514\n",
      "Iteration 37, loss = 0.25926207\n",
      "Iteration 38, loss = 0.25897937\n",
      "Iteration 39, loss = 0.25825736\n",
      "Iteration 40, loss = 0.25488328\n",
      "Iteration 41, loss = 0.25666441\n",
      "Iteration 42, loss = 0.25550850\n",
      "Iteration 43, loss = 0.25201498\n",
      "Iteration 44, loss = 0.25200140\n",
      "Iteration 45, loss = 0.24806773\n",
      "Iteration 46, loss = 0.24706817\n",
      "Iteration 47, loss = 0.24783095\n",
      "Iteration 48, loss = 0.24671741\n",
      "Iteration 49, loss = 0.24584872\n",
      "Iteration 50, loss = 0.24520216\n",
      "Iteration 51, loss = 0.24354592\n",
      "Iteration 52, loss = 0.24455887\n",
      "Iteration 53, loss = 0.24567334\n",
      "Iteration 54, loss = 0.24386672\n",
      "Iteration 55, loss = 0.24054690\n",
      "Iteration 56, loss = 0.24054547\n",
      "Iteration 57, loss = 0.23999343\n",
      "Iteration 58, loss = 0.23852901\n",
      "Iteration 59, loss = 0.23768543\n",
      "Iteration 60, loss = 0.24025489\n",
      "Iteration 61, loss = 0.23917082\n",
      "Iteration 62, loss = 0.23610545\n",
      "Iteration 63, loss = 0.23977487\n",
      "Iteration 64, loss = 0.23477216\n",
      "Iteration 65, loss = 0.23840691\n",
      "Iteration 66, loss = 0.23303215\n",
      "Iteration 67, loss = 0.23426213\n",
      "Iteration 68, loss = 0.23796738\n",
      "Iteration 69, loss = 0.23367239\n",
      "Iteration 70, loss = 0.23820141\n",
      "Iteration 71, loss = 0.23379513\n",
      "Iteration 72, loss = 0.23166075\n",
      "Iteration 73, loss = 0.23265679\n",
      "Iteration 74, loss = 0.22938468\n",
      "Iteration 75, loss = 0.23175104\n",
      "Iteration 76, loss = 0.22976307\n",
      "Iteration 77, loss = 0.22847260\n",
      "Iteration 78, loss = 0.22990191\n",
      "Iteration 79, loss = 0.22844986\n",
      "Iteration 80, loss = 0.22846769\n",
      "Iteration 81, loss = 0.22942712\n",
      "Iteration 82, loss = 0.22770356\n",
      "Iteration 83, loss = 0.23042458\n",
      "Iteration 84, loss = 0.23026743\n",
      "Iteration 85, loss = 0.22599293\n",
      "Iteration 86, loss = 0.22646731\n",
      "Iteration 87, loss = 0.22448550\n",
      "Iteration 88, loss = 0.22486435\n",
      "Iteration 89, loss = 0.22381662\n",
      "Iteration 90, loss = 0.22691185\n",
      "Iteration 91, loss = 0.22780240\n",
      "Iteration 92, loss = 0.22512649\n",
      "Iteration 93, loss = 0.22789606\n",
      "Iteration 94, loss = 0.22331415\n",
      "Iteration 95, loss = 0.22470116\n",
      "Iteration 96, loss = 0.22455213\n",
      "Iteration 97, loss = 0.22246578\n",
      "Iteration 98, loss = 0.22498322\n",
      "Iteration 99, loss = 0.22300688\n",
      "Iteration 100, loss = 0.22160031\n",
      "Iteration 1, loss = 1.45831821\n",
      "Iteration 2, loss = 1.25957590\n",
      "Iteration 3, loss = 1.10869124\n",
      "Iteration 4, loss = 0.97761760\n",
      "Iteration 5, loss = 0.84336025\n",
      "Iteration 6, loss = 0.73875857\n",
      "Iteration 7, loss = 0.64098404\n",
      "Iteration 8, loss = 0.56490935\n",
      "Iteration 9, loss = 0.50882100\n",
      "Iteration 10, loss = 0.46249378\n",
      "Iteration 11, loss = 0.43142500\n",
      "Iteration 12, loss = 0.40136536\n",
      "Iteration 13, loss = 0.37778068\n",
      "Iteration 14, loss = 0.36252709\n",
      "Iteration 15, loss = 0.34871532\n",
      "Iteration 16, loss = 0.34168719\n",
      "Iteration 17, loss = 0.32819061\n",
      "Iteration 18, loss = 0.32083401\n",
      "Iteration 19, loss = 0.31408394\n",
      "Iteration 20, loss = 0.31232560\n",
      "Iteration 21, loss = 0.30475055\n",
      "Iteration 22, loss = 0.30228179\n",
      "Iteration 23, loss = 0.29653517\n",
      "Iteration 24, loss = 0.30086439\n",
      "Iteration 25, loss = 0.29689552\n",
      "Iteration 26, loss = 0.28963914\n",
      "Iteration 27, loss = 0.28472185\n",
      "Iteration 28, loss = 0.28160527\n",
      "Iteration 29, loss = 0.28150249\n",
      "Iteration 30, loss = 0.28406904\n",
      "Iteration 31, loss = 0.27675024\n",
      "Iteration 32, loss = 0.28028309\n",
      "Iteration 33, loss = 0.26890742\n",
      "Iteration 34, loss = 0.26940102\n",
      "Iteration 35, loss = 0.27073849\n",
      "Iteration 36, loss = 0.26529933\n",
      "Iteration 37, loss = 0.27029320\n",
      "Iteration 38, loss = 0.26873103\n",
      "Iteration 39, loss = 0.26264043\n",
      "Iteration 40, loss = 0.26310443\n",
      "Iteration 41, loss = 0.25798454\n",
      "Iteration 42, loss = 0.25622751\n",
      "Iteration 43, loss = 0.26411320\n",
      "Iteration 44, loss = 0.25635498\n",
      "Iteration 45, loss = 0.25581954\n",
      "Iteration 46, loss = 0.25592240\n",
      "Iteration 47, loss = 0.25323165\n",
      "Iteration 48, loss = 0.25334538\n",
      "Iteration 49, loss = 0.25056387\n",
      "Iteration 50, loss = 0.24878783\n",
      "Iteration 51, loss = 0.24840894\n",
      "Iteration 52, loss = 0.25065336\n",
      "Iteration 53, loss = 0.24672083\n",
      "Iteration 54, loss = 0.24594461\n",
      "Iteration 55, loss = 0.24624577\n",
      "Iteration 56, loss = 0.24516846\n",
      "Iteration 57, loss = 0.24263129\n",
      "Iteration 58, loss = 0.24074333\n",
      "Iteration 59, loss = 0.24440684\n",
      "Iteration 60, loss = 0.24540815\n",
      "Iteration 61, loss = 0.23965620\n",
      "Iteration 62, loss = 0.23857977\n",
      "Iteration 63, loss = 0.24122718\n",
      "Iteration 64, loss = 0.24112236\n",
      "Iteration 65, loss = 0.23752948\n",
      "Iteration 66, loss = 0.23592149\n",
      "Iteration 67, loss = 0.23702683\n",
      "Iteration 68, loss = 0.23583748\n",
      "Iteration 69, loss = 0.23607528\n",
      "Iteration 70, loss = 0.24334044\n",
      "Iteration 71, loss = 0.23988234\n",
      "Iteration 72, loss = 0.23679249\n",
      "Iteration 73, loss = 0.23271673\n",
      "Iteration 74, loss = 0.23892988\n",
      "Iteration 75, loss = 0.23475926\n",
      "Iteration 76, loss = 0.23199971\n",
      "Iteration 77, loss = 0.23093997\n",
      "Iteration 78, loss = 0.23161263\n",
      "Iteration 79, loss = 0.23544851\n",
      "Iteration 80, loss = 0.23138282\n",
      "Iteration 81, loss = 0.23485281\n",
      "Iteration 82, loss = 0.23106868\n",
      "Iteration 83, loss = 0.23256149\n",
      "Iteration 84, loss = 0.23271230\n",
      "Iteration 85, loss = 0.23453033\n",
      "Iteration 86, loss = 0.23024711\n",
      "Iteration 87, loss = 0.23250501\n",
      "Iteration 88, loss = 0.23504020\n",
      "Iteration 89, loss = 0.23527789\n",
      "Iteration 90, loss = 0.23285371\n",
      "Iteration 91, loss = 0.22876332\n",
      "Iteration 92, loss = 0.22851105\n",
      "Iteration 93, loss = 0.22906982\n",
      "Iteration 94, loss = 0.22708716\n",
      "Iteration 95, loss = 0.23471261\n",
      "Iteration 96, loss = 0.23080380\n",
      "Iteration 97, loss = 0.23202264\n",
      "Iteration 98, loss = 0.22791733\n",
      "Iteration 99, loss = 0.22613234\n",
      "Iteration 100, loss = 0.22429409\n",
      "Iteration 1, loss = 1.41216196\n",
      "Iteration 2, loss = 1.32669059\n",
      "Iteration 3, loss = 1.22934095\n",
      "Iteration 4, loss = 1.13320544\n",
      "Iteration 5, loss = 1.02500704\n",
      "Iteration 6, loss = 0.89851196\n",
      "Iteration 7, loss = 0.77509528\n",
      "Iteration 8, loss = 0.65332524\n",
      "Iteration 9, loss = 0.55380579\n",
      "Iteration 10, loss = 0.48417121\n",
      "Iteration 11, loss = 0.42991237\n",
      "Iteration 12, loss = 0.38775135\n",
      "Iteration 13, loss = 0.36282568\n",
      "Iteration 14, loss = 0.34017141\n",
      "Iteration 15, loss = 0.32147216\n",
      "Iteration 16, loss = 0.30877733\n",
      "Iteration 17, loss = 0.29914582\n",
      "Iteration 18, loss = 0.28999861\n",
      "Iteration 19, loss = 0.28618369\n",
      "Iteration 20, loss = 0.27361032\n",
      "Iteration 21, loss = 0.27323672\n",
      "Iteration 22, loss = 0.26175931\n",
      "Iteration 23, loss = 0.25712720\n",
      "Iteration 24, loss = 0.25621195\n",
      "Iteration 25, loss = 0.25769470\n",
      "Iteration 26, loss = 0.24516912\n",
      "Iteration 27, loss = 0.24666499\n",
      "Iteration 28, loss = 0.23962956\n",
      "Iteration 29, loss = 0.23704368\n",
      "Iteration 30, loss = 0.23689530\n",
      "Iteration 31, loss = 0.23566371\n",
      "Iteration 32, loss = 0.23087787\n",
      "Iteration 33, loss = 0.23092637\n",
      "Iteration 34, loss = 0.23094919\n",
      "Iteration 35, loss = 0.23024070\n",
      "Iteration 36, loss = 0.23351251\n",
      "Iteration 37, loss = 0.22794455\n",
      "Iteration 38, loss = 0.22632248\n",
      "Iteration 39, loss = 0.22417841\n",
      "Iteration 40, loss = 0.22413946\n",
      "Iteration 41, loss = 0.22319942\n",
      "Iteration 42, loss = 0.22001952\n",
      "Iteration 43, loss = 0.22127341\n",
      "Iteration 44, loss = 0.22112589\n",
      "Iteration 45, loss = 0.21881940\n",
      "Iteration 46, loss = 0.21858222\n",
      "Iteration 47, loss = 0.21758761\n",
      "Iteration 48, loss = 0.22392751\n",
      "Iteration 49, loss = 0.21826475\n",
      "Iteration 50, loss = 0.21554568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 51, loss = 0.21749326\n",
      "Iteration 52, loss = 0.21345530\n",
      "Iteration 53, loss = 0.21255362\n",
      "Iteration 54, loss = 0.21737984\n",
      "Iteration 55, loss = 0.21326549\n",
      "Iteration 56, loss = 0.21146294\n",
      "Iteration 57, loss = 0.22256648\n",
      "Iteration 58, loss = 0.21425779\n",
      "Iteration 59, loss = 0.21285368\n",
      "Iteration 60, loss = 0.21335913\n",
      "Iteration 61, loss = 0.21119751\n",
      "Iteration 62, loss = 0.21346375\n",
      "Iteration 63, loss = 0.21126540\n",
      "Iteration 64, loss = 0.21017413\n",
      "Iteration 65, loss = 0.21380068\n",
      "Iteration 66, loss = 0.20958600\n",
      "Iteration 67, loss = 0.21091011\n",
      "Iteration 68, loss = 0.20879902\n",
      "Iteration 69, loss = 0.21163656\n",
      "Iteration 70, loss = 0.20900255\n",
      "Iteration 71, loss = 0.20622851\n",
      "Iteration 72, loss = 0.20770499\n",
      "Iteration 73, loss = 0.21033854\n",
      "Iteration 74, loss = 0.20798989\n",
      "Iteration 75, loss = 0.21054907\n",
      "Iteration 76, loss = 0.20726597\n",
      "Iteration 77, loss = 0.20945305\n",
      "Iteration 78, loss = 0.20878643\n",
      "Iteration 79, loss = 0.20590703\n",
      "Iteration 80, loss = 0.21082387\n",
      "Iteration 81, loss = 0.20843231\n",
      "Iteration 82, loss = 0.20654914\n",
      "Iteration 83, loss = 0.20631920\n",
      "Iteration 84, loss = 0.20683059\n",
      "Iteration 85, loss = 0.20611760\n",
      "Iteration 86, loss = 0.20714497\n",
      "Iteration 87, loss = 0.21147765\n",
      "Iteration 88, loss = 0.21041662\n",
      "Iteration 89, loss = 0.20732141\n",
      "Iteration 90, loss = 0.20652825\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Train Accuracy: 92.0%\n",
      "Train Accuracy: 88.0%\n",
      "Train Accuracy: 88.0%\n",
      "INPUT:  [[1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[{'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.259, 0.557, 0.074, 0.109]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.262, 0.283, 0.205, 0.25 ]), 'nn': array([0.181, 0.656, 0.068, 0.095]), 'svc': array([0.361, 0.531, 0.024, 0.085]), 'nb': array([0.232, 0.759, 0.001, 0.008])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.279, 0.353, 0.285]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.091, 0.315, 0.192, 0.401]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.462, 0.088, 0.361, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.376, 0.087, 0.434, 0.103]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.104, 0.083, 0.155, 0.659]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.083, 0.087, 0.077, 0.754]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.676, 0.136, 0.079, 0.109]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.766, 0.078, 0.065, 0.091]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.089, 0.1  , 0.611, 0.201]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.225, 0.239, 0.264, 0.272]), 'nn': array([0.077, 0.084, 0.744, 0.095]), 'svc': array([0.043, 0.031, 0.626, 0.3  ]), 'nb': array([0.01 , 0.045, 0.809, 0.136])}}, {'ensemble_proba': array([0.109, 0.513, 0.08 , 0.299]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.232, 0.278, 0.218, 0.272]), 'nn': array([0.091, 0.379, 0.075, 0.455]), 'svc': array([0.093, 0.592, 0.023, 0.293]), 'nb': array([0.02 , 0.802, 0.002, 0.175])}}, {'ensemble_proba': array([0.083, 0.279, 0.353, 0.285]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.091, 0.315, 0.192, 0.401]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.438, 0.228, 0.093, 0.241]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.517, 0.097, 0.076, 0.31 ]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.462, 0.088, 0.361, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.376, 0.087, 0.434, 0.103]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.201, 0.59 , 0.094, 0.115]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.267, 0.234, 0.251]), 'nn': array([0.104, 0.711, 0.072, 0.113]), 'svc': array([0.281, 0.603, 0.047, 0.069]), 'nb': array([0.17 , 0.779, 0.024, 0.027])}}, {'ensemble_proba': array([0.462, 0.088, 0.361, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.376, 0.087, 0.434, 0.103]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.209, 0.08 , 0.566, 0.145]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.259, 0.217, 0.258, 0.267]), 'nn': array([0.091, 0.083, 0.731, 0.095]), 'svc': array([0.245, 0.011, 0.609, 0.135]), 'nb': array([0.243, 0.007, 0.665, 0.085])}}, {'ensemble_proba': array([0.462, 0.088, 0.361, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.376, 0.087, 0.434, 0.103]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.17 , 0.642, 0.093, 0.095]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.095, 0.744, 0.067, 0.094]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.17 , 0.642, 0.093, 0.095]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.095, 0.744, 0.067, 0.094]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.17 , 0.642, 0.093, 0.095]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.095, 0.744, 0.067, 0.094]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.676, 0.136, 0.079, 0.109]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.766, 0.078, 0.065, 0.091]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.462, 0.088, 0.361, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.376, 0.087, 0.434, 0.103]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.081, 0.139, 0.095, 0.684]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.213, 0.248, 0.218, 0.32 ]), 'nn': array([0.082, 0.092, 0.071, 0.754]), 'svc': array([0.031, 0.193, 0.089, 0.687]), 'nb': array([0.001, 0.021, 0.003, 0.976])}}, {'ensemble_proba': array([0.087, 0.66 , 0.073, 0.18 ]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.076, 0.765, 0.066, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.668, 0.137, 0.112, 0.083]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.297, 0.244, 0.244, 0.215]), 'nn': array([0.752, 0.09 , 0.066, 0.092]), 'svc': array([0.661, 0.195, 0.117, 0.027]), 'nb': array([0.962, 0.018, 0.02 , 0.   ])}}, {'ensemble_proba': array([0.086, 0.122, 0.646, 0.145]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.232, 0.238, 0.273, 0.258]), 'nn': array([0.081, 0.086, 0.686, 0.146]), 'svc': array([0.03 , 0.156, 0.683, 0.131]), 'nb': array([0.004, 0.01 , 0.943, 0.043])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.087, 0.66 , 0.073, 0.18 ]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.076, 0.765, 0.066, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.189, 0.096, 0.084, 0.63 ]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.244, 0.236, 0.225, 0.295]), 'nn': array([0.118, 0.088, 0.075, 0.72 ]), 'svc': array([0.296, 0.046, 0.026, 0.632]), 'nb': array([0.1  , 0.014, 0.011, 0.875])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.438, 0.228, 0.093, 0.241]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.517, 0.097, 0.076, 0.31 ]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.124, 0.122, 0.164, 0.59 ]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.106, 0.19 , 0.184, 0.52 ]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.629, 0.099, 0.09 , 0.182]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.27 , 0.238, 0.223, 0.269]), 'nn': array([0.754, 0.087, 0.067, 0.093]), 'svc': array([0.625, 0.025, 0.05 , 0.3  ]), 'nb': array([0.868, 0.046, 0.02 , 0.066])}}, {'ensemble_proba': array([0.087, 0.66 , 0.073, 0.18 ]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.076, 0.765, 0.066, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.104, 0.083, 0.155, 0.659]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.083, 0.087, 0.077, 0.754]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.395, 0.31 , 0.207, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.262, 0.255, 0.256, 0.227]), 'nn': array([0.563, 0.255, 0.089, 0.093]), 'svc': array([0.368, 0.416, 0.19 , 0.026]), 'nb': array([0.387, 0.316, 0.294, 0.003])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.105, 0.074, 0.65 , 0.17 ]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.246, 0.205, 0.284, 0.265]), 'nn': array([0.077, 0.082, 0.747, 0.093]), 'svc': array([0.085, 0.01 , 0.608, 0.296]), 'nb': array([0.013, 0.   , 0.96 , 0.027])}}, {'ensemble_proba': array([0.087, 0.66 , 0.073, 0.18 ]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.076, 0.765, 0.066, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.156, 0.084, 0.677, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.269, 0.209, 0.312, 0.21 ]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.271, 0.044, 0.657, 0.027]), 'nb': array([0.007, 0.   , 0.993, 0.   ])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.578, 0.085, 0.099, 0.238]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.272, 0.224, 0.227, 0.277]), 'nn': array([0.676, 0.088, 0.078, 0.158]), 'svc': array([0.555, 0.016, 0.068, 0.361]), 'nb': array([0.808, 0.012, 0.023, 0.157])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.436, 0.136, 0.075, 0.352]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.248, 0.203, 0.295]), 'nn': array([0.628, 0.101, 0.073, 0.198]), 'svc': array([0.508, 0.09 , 0.024, 0.378]), 'nb': array([0.355, 0.106, 0.001, 0.538])}}, {'ensemble_proba': array([0.084, 0.156, 0.648, 0.112]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.079, 0.095, 0.728, 0.099]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.089, 0.1  , 0.611, 0.201]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.225, 0.239, 0.264, 0.272]), 'nn': array([0.077, 0.084, 0.744, 0.095]), 'svc': array([0.043, 0.031, 0.626, 0.3  ]), 'nb': array([0.01 , 0.045, 0.809, 0.136])}}, {'ensemble_proba': array([0.124, 0.122, 0.164, 0.59 ]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.106, 0.19 , 0.184, 0.52 ]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.124, 0.122, 0.164, 0.59 ]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.106, 0.19 , 0.184, 0.52 ]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.084, 0.156, 0.648, 0.112]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.079, 0.095, 0.728, 0.099]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.087, 0.66 , 0.073, 0.18 ]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.076, 0.765, 0.066, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.087, 0.66 , 0.073, 0.18 ]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.076, 0.765, 0.066, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.438, 0.228, 0.093, 0.241]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.517, 0.097, 0.076, 0.31 ]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.658, 0.073, 0.113, 0.156]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.295, 0.204, 0.24 , 0.261]), 'nn': array([0.76 , 0.078, 0.071, 0.091]), 'svc': array([0.608, 0.011, 0.121, 0.26 ]), 'nb': array([0.968, 0.   , 0.02 , 0.011])}}, {'ensemble_proba': array([0.156, 0.084, 0.678, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.269, 0.209, 0.312, 0.21 ]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.271, 0.044, 0.657, 0.027]), 'nb': array([0.007, 0.   , 0.993, 0.   ])}}, {'ensemble_proba': array([0.164, 0.458, 0.131, 0.247]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.252, 0.244, 0.255]), 'nn': array([0.119, 0.579, 0.089, 0.213]), 'svc': array([0.082, 0.591, 0.037, 0.291]), 'nb': array([0.205, 0.41 , 0.155, 0.23 ])}}, {'ensemble_proba': array([0.676, 0.083, 0.16 , 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.765, 0.078, 0.066, 0.091]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.084, 0.172, 0.091, 0.653]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.211, 0.263, 0.214, 0.313]), 'nn': array([0.083, 0.111, 0.072, 0.734]), 'svc': array([0.041, 0.223, 0.075, 0.662]), 'nb': array([0.001, 0.091, 0.003, 0.905])}}, {'ensemble_proba': array([0.124, 0.122, 0.164, 0.59 ]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.106, 0.19 , 0.184, 0.52 ]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.081, 0.139, 0.095, 0.684]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.213, 0.248, 0.218, 0.32 ]), 'nn': array([0.082, 0.092, 0.071, 0.754]), 'svc': array([0.031, 0.193, 0.089, 0.687]), 'nb': array([0.001, 0.021, 0.003, 0.976])}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 0, 3, 2, 0, 3, 0, 2, 1, 2, 0, 0, 2, 3, 1, 0, 0, 2, 0, 1,\n",
       "       2, 3, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 0, 0, 2, 0, 1, 3, 1, 0, 2,\n",
       "       3, 1, 3, 1, 0, 3, 0, 1, 0, 3, 3, 3, 0, 0, 0, 2, 1, 2, 1, 1, 2, 0,\n",
       "       0, 0, 0, 2, 1, 3, 2, 2, 3, 3, 1, 3, 2, 1, 3, 1, 1, 0, 3, 3, 0, 2,\n",
       "       1, 0, 1, 3, 3, 2, 1, 3, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import classifierAgents\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "file = '/Users/youssefawad/Documents/Kings/term_2/6CCS3ML1_Machine_Learning/coursework/cw1_pacman/good-moves.txt'\n",
    "\n",
    "data, target = classifierAgents.loadData(file)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "from classifier import Classifier\n",
    "\n",
    "clf = Classifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbd4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  [[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[{'ensemble_proba': array([0.462, 0.088, 0.361, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.376, 0.087, 0.434, 0.103]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.121, 0.127, 0.667, 0.085]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.248, 0.245, 0.289, 0.218]), 'nn': array([0.081, 0.085, 0.74 , 0.094]), 'svc': array([0.143, 0.156, 0.674, 0.027]), 'nb': array([0.013, 0.021, 0.965, 0.   ])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.084, 0.156, 0.648, 0.112]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.079, 0.095, 0.728, 0.099]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.438, 0.228, 0.093, 0.241]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.517, 0.097, 0.076, 0.31 ]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.159, 0.084, 0.674, 0.083]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.077, 0.082, 0.748, 0.093]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.164, 0.458, 0.131, 0.247]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.252, 0.244, 0.255]), 'nn': array([0.119, 0.579, 0.089, 0.213]), 'svc': array([0.082, 0.591, 0.037, 0.291]), 'nb': array([0.205, 0.41 , 0.155, 0.23 ])}}, {'ensemble_proba': array([0.676, 0.136, 0.079, 0.109]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.766, 0.078, 0.065, 0.091]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.087, 0.66 , 0.073, 0.18 ]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.076, 0.765, 0.066, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.279, 0.353, 0.285]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.091, 0.315, 0.192, 0.401]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.079, 0.1  , 0.226, 0.595]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.203, 0.24 , 0.248, 0.309]), 'nn': array([0.086, 0.097, 0.201, 0.616]), 'svc': array([0.026, 0.045, 0.326, 0.602]), 'nb': array([0.   , 0.02 , 0.127, 0.853])}}, {'ensemble_proba': array([0.104, 0.083, 0.155, 0.659]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.083, 0.087, 0.077, 0.754]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.629, 0.099, 0.09 , 0.182]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.27 , 0.238, 0.223, 0.269]), 'nn': array([0.754, 0.087, 0.067, 0.093]), 'svc': array([0.625, 0.025, 0.05 , 0.3  ]), 'nb': array([0.868, 0.046, 0.02 , 0.066])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.087, 0.66 , 0.073, 0.18 ]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.076, 0.765, 0.066, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.462, 0.088, 0.361, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.376, 0.087, 0.434, 0.103]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.124, 0.122, 0.164, 0.59 ]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.106, 0.19 , 0.184, 0.52 ]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.083, 0.279, 0.353, 0.285]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.091, 0.315, 0.192, 0.401]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.082, 0.298, 0.076, 0.544]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.196, 0.287, 0.19 , 0.327]), 'nn': array([0.081, 0.316, 0.071, 0.532]), 'svc': array([0.051, 0.255, 0.043, 0.651]), 'nb': array([0.   , 0.333, 0.   , 0.667])}}, {'ensemble_proba': array([0.083, 0.163, 0.077, 0.677]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.082, 0.087, 0.071, 0.76 ]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.092, 0.578, 0.073, 0.257]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.079, 0.693, 0.069, 0.16 ]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}]\n",
      "Test Accuracy: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "accuracy = np.mean(preds == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b9e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  [[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[{'ensemble_proba': array([0.462, 0.088, 0.361, 0.088]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.376, 0.087, 0.434, 0.103]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f6f963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d8e6d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.57773371\n",
      "Iteration 2, loss = 1.38324963\n",
      "Iteration 3, loss = 1.27293037\n",
      "Iteration 4, loss = 1.16908972\n",
      "Iteration 5, loss = 1.05820575\n",
      "Iteration 6, loss = 0.93778751\n",
      "Iteration 7, loss = 0.81635228\n",
      "Iteration 8, loss = 0.73075190\n",
      "Iteration 9, loss = 0.64151220\n",
      "Iteration 10, loss = 0.57850658\n",
      "Iteration 11, loss = 0.52577489\n",
      "Iteration 12, loss = 0.48122219\n",
      "Iteration 13, loss = 0.44283077\n",
      "Iteration 14, loss = 0.41074885\n",
      "Iteration 15, loss = 0.38293944\n",
      "Iteration 16, loss = 0.35789646\n",
      "Iteration 17, loss = 0.33847164\n",
      "Iteration 18, loss = 0.32633449\n",
      "Iteration 19, loss = 0.31470762\n",
      "Iteration 20, loss = 0.30532769\n",
      "Iteration 21, loss = 0.29808949\n",
      "Iteration 22, loss = 0.29261022\n",
      "Iteration 23, loss = 0.29191503\n",
      "Iteration 24, loss = 0.28054350\n",
      "Iteration 25, loss = 0.28442914\n",
      "Iteration 26, loss = 0.27366245\n",
      "Iteration 27, loss = 0.27177882\n",
      "Iteration 28, loss = 0.27138257\n",
      "Iteration 29, loss = 0.26709493\n",
      "Iteration 30, loss = 0.26410236\n",
      "Iteration 31, loss = 0.26220619\n",
      "Iteration 32, loss = 0.26093162\n",
      "Iteration 33, loss = 0.25750381\n",
      "Iteration 34, loss = 0.25700202\n",
      "Iteration 35, loss = 0.25342194\n",
      "Iteration 36, loss = 0.25302049\n",
      "Iteration 37, loss = 0.25408406\n",
      "Iteration 38, loss = 0.24985612\n",
      "Iteration 39, loss = 0.24808516\n",
      "Iteration 40, loss = 0.24695894\n",
      "Iteration 41, loss = 0.24562930\n",
      "Iteration 42, loss = 0.24417055\n",
      "Iteration 43, loss = 0.24258550\n",
      "Iteration 44, loss = 0.24018212\n",
      "Iteration 45, loss = 0.24081903\n",
      "Iteration 46, loss = 0.23992484\n",
      "Iteration 47, loss = 0.23653057\n",
      "Iteration 48, loss = 0.23815234\n",
      "Iteration 49, loss = 0.23711217\n",
      "Iteration 50, loss = 0.23533691\n",
      "Iteration 51, loss = 0.23227428\n",
      "Iteration 52, loss = 0.23300345\n",
      "Iteration 53, loss = 0.23211059\n",
      "Iteration 54, loss = 0.23042825\n",
      "Iteration 55, loss = 0.22838787\n",
      "Iteration 56, loss = 0.22857775\n",
      "Iteration 57, loss = 0.23135105\n",
      "Iteration 58, loss = 0.22732491\n",
      "Iteration 59, loss = 0.22650204\n",
      "Iteration 60, loss = 0.22555372\n",
      "Iteration 61, loss = 0.22344467\n",
      "Iteration 62, loss = 0.22377714\n",
      "Iteration 63, loss = 0.22481041\n",
      "Iteration 64, loss = 0.22477836\n",
      "Iteration 65, loss = 0.22140207\n",
      "Iteration 66, loss = 0.22061882\n",
      "Iteration 67, loss = 0.21968849\n",
      "Iteration 68, loss = 0.22064780\n",
      "Iteration 69, loss = 0.21857595\n",
      "Iteration 70, loss = 0.21732391\n",
      "Iteration 71, loss = 0.22362060\n",
      "Iteration 72, loss = 0.21690985\n",
      "Iteration 73, loss = 0.21817658\n",
      "Iteration 74, loss = 0.21485738\n",
      "Iteration 75, loss = 0.21700021\n",
      "Iteration 76, loss = 0.21878051\n",
      "Iteration 77, loss = 0.21672469\n",
      "Iteration 78, loss = 0.21802869\n",
      "Iteration 79, loss = 0.21506874\n",
      "Iteration 80, loss = 0.21220717\n",
      "Iteration 81, loss = 0.21808260\n",
      "Iteration 82, loss = 0.21702560\n",
      "Iteration 83, loss = 0.21573213\n",
      "Iteration 84, loss = 0.21246365\n",
      "Iteration 85, loss = 0.21703457\n",
      "Iteration 86, loss = 0.21097294\n",
      "Iteration 87, loss = 0.20955648\n",
      "Iteration 88, loss = 0.21290124\n",
      "Iteration 89, loss = 0.21657349\n",
      "Iteration 90, loss = 0.21093886\n",
      "Iteration 91, loss = 0.21170749\n",
      "Iteration 92, loss = 0.21217846\n",
      "Iteration 93, loss = 0.21048743\n",
      "Iteration 94, loss = 0.20825887\n",
      "Iteration 95, loss = 0.21163308\n",
      "Iteration 96, loss = 0.20915833\n",
      "Iteration 97, loss = 0.21202844\n",
      "Iteration 98, loss = 0.20627657\n",
      "Iteration 99, loss = 0.20614144\n",
      "Iteration 100, loss = 0.20961009\n",
      "Iteration 1, loss = 1.54871876\n",
      "Iteration 2, loss = 1.35539656\n",
      "Iteration 3, loss = 1.20782051\n",
      "Iteration 4, loss = 1.06590989\n",
      "Iteration 5, loss = 0.94429332\n",
      "Iteration 6, loss = 0.81826434\n",
      "Iteration 7, loss = 0.72062160\n",
      "Iteration 8, loss = 0.63720199\n",
      "Iteration 9, loss = 0.57006642\n",
      "Iteration 10, loss = 0.52263293\n",
      "Iteration 11, loss = 0.48612371\n",
      "Iteration 12, loss = 0.45854777\n",
      "Iteration 13, loss = 0.43817269\n",
      "Iteration 14, loss = 0.42127344\n",
      "Iteration 15, loss = 0.40758099\n",
      "Iteration 16, loss = 0.40487568\n",
      "Iteration 17, loss = 0.38395126\n",
      "Iteration 18, loss = 0.37704006\n",
      "Iteration 19, loss = 0.36889599\n",
      "Iteration 20, loss = 0.36168343\n",
      "Iteration 21, loss = 0.35638443\n",
      "Iteration 22, loss = 0.35143367\n",
      "Iteration 23, loss = 0.34791621\n",
      "Iteration 24, loss = 0.34474059\n",
      "Iteration 25, loss = 0.33945291\n",
      "Iteration 26, loss = 0.33654384\n",
      "Iteration 27, loss = 0.33182380\n",
      "Iteration 28, loss = 0.32904006\n",
      "Iteration 29, loss = 0.32870526\n",
      "Iteration 30, loss = 0.32263277\n",
      "Iteration 31, loss = 0.32077266\n",
      "Iteration 32, loss = 0.31762407\n",
      "Iteration 33, loss = 0.31466578\n",
      "Iteration 34, loss = 0.31244000\n",
      "Iteration 35, loss = 0.31048901\n",
      "Iteration 36, loss = 0.30722184\n",
      "Iteration 37, loss = 0.30645167\n",
      "Iteration 38, loss = 0.30254080\n",
      "Iteration 39, loss = 0.30247425\n",
      "Iteration 40, loss = 0.30061011\n",
      "Iteration 41, loss = 0.29834962\n",
      "Iteration 42, loss = 0.30070412\n",
      "Iteration 43, loss = 0.29766716\n",
      "Iteration 44, loss = 0.29508231\n",
      "Iteration 45, loss = 0.29328665\n",
      "Iteration 46, loss = 0.29358182\n",
      "Iteration 47, loss = 0.29113430\n",
      "Iteration 48, loss = 0.28992118\n",
      "Iteration 49, loss = 0.29285885\n",
      "Iteration 50, loss = 0.28927632\n",
      "Iteration 51, loss = 0.28549246\n",
      "Iteration 52, loss = 0.28672905\n",
      "Iteration 53, loss = 0.28522468\n",
      "Iteration 54, loss = 0.28208909\n",
      "Iteration 55, loss = 0.28310769\n",
      "Iteration 56, loss = 0.28085384\n",
      "Iteration 57, loss = 0.27878221\n",
      "Iteration 58, loss = 0.27970048\n",
      "Iteration 59, loss = 0.27842272\n",
      "Iteration 60, loss = 0.27884122\n",
      "Iteration 61, loss = 0.27734016\n",
      "Iteration 62, loss = 0.27842551\n",
      "Iteration 63, loss = 0.27845665\n",
      "Iteration 64, loss = 0.27407021\n",
      "Iteration 65, loss = 0.27345281\n",
      "Iteration 66, loss = 0.27310778\n",
      "Iteration 67, loss = 0.27498967\n",
      "Iteration 68, loss = 0.27210590\n",
      "Iteration 69, loss = 0.27364747\n",
      "Iteration 70, loss = 0.27543707\n",
      "Iteration 71, loss = 0.27025195\n",
      "Iteration 72, loss = 0.27303593\n",
      "Iteration 73, loss = 0.26900980\n",
      "Iteration 74, loss = 0.27481505\n",
      "Iteration 75, loss = 0.26893694\n",
      "Iteration 76, loss = 0.27038985\n",
      "Iteration 77, loss = 0.27046538\n",
      "Iteration 78, loss = 0.26864667\n",
      "Iteration 79, loss = 0.27106252\n",
      "Iteration 80, loss = 0.26600028\n",
      "Iteration 81, loss = 0.26739153\n",
      "Iteration 82, loss = 0.26623812\n",
      "Iteration 83, loss = 0.26978357\n",
      "Iteration 84, loss = 0.26929958\n",
      "Iteration 85, loss = 0.26572016\n",
      "Iteration 86, loss = 0.26748512\n",
      "Iteration 87, loss = 0.26947078\n",
      "Iteration 88, loss = 0.26369061\n",
      "Iteration 89, loss = 0.26516044\n",
      "Iteration 90, loss = 0.26497890\n",
      "Iteration 91, loss = 0.26355820\n",
      "Iteration 92, loss = 0.26707311\n",
      "Iteration 93, loss = 0.26448171\n",
      "Iteration 94, loss = 0.26115272\n",
      "Iteration 95, loss = 0.26956395\n",
      "Iteration 96, loss = 0.26394723\n",
      "Iteration 97, loss = 0.26211922\n",
      "Iteration 98, loss = 0.26001396\n",
      "Iteration 99, loss = 0.26436300\n",
      "Iteration 100, loss = 0.26047231\n",
      "Iteration 1, loss = 1.41796174\n",
      "Iteration 2, loss = 1.34744941\n",
      "Iteration 3, loss = 1.26989506\n",
      "Iteration 4, loss = 1.18023330\n",
      "Iteration 5, loss = 1.05343163\n",
      "Iteration 6, loss = 0.93164527\n",
      "Iteration 7, loss = 0.80730699\n",
      "Iteration 8, loss = 0.70375750\n",
      "Iteration 9, loss = 0.60907399\n",
      "Iteration 10, loss = 0.53629516\n",
      "Iteration 11, loss = 0.48565906\n",
      "Iteration 12, loss = 0.45311972\n",
      "Iteration 13, loss = 0.42315220\n",
      "Iteration 14, loss = 0.40572727\n",
      "Iteration 15, loss = 0.39307857\n",
      "Iteration 16, loss = 0.37521258\n",
      "Iteration 17, loss = 0.36429679\n",
      "Iteration 18, loss = 0.35177970\n",
      "Iteration 19, loss = 0.34240910\n",
      "Iteration 20, loss = 0.33345886\n",
      "Iteration 21, loss = 0.32807481\n",
      "Iteration 22, loss = 0.31853518\n",
      "Iteration 23, loss = 0.31230706\n",
      "Iteration 24, loss = 0.30870246\n",
      "Iteration 25, loss = 0.29775604\n",
      "Iteration 26, loss = 0.29491795\n",
      "Iteration 27, loss = 0.29230003\n",
      "Iteration 28, loss = 0.28835557\n",
      "Iteration 29, loss = 0.28074824\n",
      "Iteration 30, loss = 0.28410643\n",
      "Iteration 31, loss = 0.27713285\n",
      "Iteration 32, loss = 0.27741578\n",
      "Iteration 33, loss = 0.27454978\n",
      "Iteration 34, loss = 0.26707416\n",
      "Iteration 35, loss = 0.26316128\n",
      "Iteration 36, loss = 0.26391680\n",
      "Iteration 37, loss = 0.26012958\n",
      "Iteration 38, loss = 0.25833702\n",
      "Iteration 39, loss = 0.25664932\n",
      "Iteration 40, loss = 0.25547032\n",
      "Iteration 41, loss = 0.25853451\n",
      "Iteration 42, loss = 0.25498200\n",
      "Iteration 43, loss = 0.24893448\n",
      "Iteration 44, loss = 0.24809126\n",
      "Iteration 45, loss = 0.24727212\n",
      "Iteration 46, loss = 0.24519452\n",
      "Iteration 47, loss = 0.24693943\n",
      "Iteration 48, loss = 0.24405625\n",
      "Iteration 49, loss = 0.24503016\n",
      "Iteration 50, loss = 0.24263130\n",
      "Iteration 51, loss = 0.24046541\n",
      "Iteration 52, loss = 0.24281665\n",
      "Iteration 53, loss = 0.24188646\n",
      "Iteration 54, loss = 0.23897445\n",
      "Iteration 55, loss = 0.23801096\n",
      "Iteration 56, loss = 0.23974545\n",
      "Iteration 57, loss = 0.23663021\n",
      "Iteration 58, loss = 0.23700835\n",
      "Iteration 59, loss = 0.23657491\n",
      "Iteration 60, loss = 0.23438831\n",
      "Iteration 61, loss = 0.23341707\n",
      "Iteration 62, loss = 0.23550143\n",
      "Iteration 63, loss = 0.23136276\n",
      "Iteration 64, loss = 0.23546338\n",
      "Iteration 65, loss = 0.23348744\n",
      "Iteration 66, loss = 0.23133641\n",
      "Iteration 67, loss = 0.23127714\n",
      "Iteration 68, loss = 0.23178550\n",
      "Iteration 69, loss = 0.23062889\n",
      "Iteration 70, loss = 0.23039992\n",
      "Iteration 71, loss = 0.23117726\n",
      "Iteration 72, loss = 0.23019253\n",
      "Iteration 73, loss = 0.22818650\n",
      "Iteration 74, loss = 0.23204841\n",
      "Iteration 75, loss = 0.23041384\n",
      "Iteration 76, loss = 0.23109714\n",
      "Iteration 77, loss = 0.22734665\n",
      "Iteration 78, loss = 0.22920081\n",
      "Iteration 79, loss = 0.22800254\n",
      "Iteration 80, loss = 0.22613634\n",
      "Iteration 81, loss = 0.22953928\n",
      "Iteration 82, loss = 0.22890734\n",
      "Iteration 83, loss = 0.22591119\n",
      "Iteration 84, loss = 0.22533313\n",
      "Iteration 85, loss = 0.22467414\n",
      "Iteration 86, loss = 0.22651821\n",
      "Iteration 87, loss = 0.22531446\n",
      "Iteration 88, loss = 0.22520771\n",
      "Iteration 89, loss = 0.22563815\n",
      "Iteration 90, loss = 0.22393963\n",
      "Iteration 91, loss = 0.22368820\n",
      "Iteration 92, loss = 0.22443170\n",
      "Iteration 93, loss = 0.22296246\n",
      "Iteration 94, loss = 0.22305985\n",
      "Iteration 95, loss = 0.22639380\n",
      "Iteration 96, loss = 0.22172093\n",
      "Iteration 97, loss = 0.22302726\n",
      "Iteration 98, loss = 0.22179228\n",
      "Iteration 99, loss = 0.22414759\n",
      "Iteration 100, loss = 0.22077529\n",
      "Iteration 1, loss = 1.58546065\n",
      "Iteration 2, loss = 1.35452767\n",
      "Iteration 3, loss = 1.21758118\n",
      "Iteration 4, loss = 1.09521364\n",
      "Iteration 5, loss = 0.98544274\n",
      "Iteration 6, loss = 0.87710656\n",
      "Iteration 7, loss = 0.78470886\n",
      "Iteration 8, loss = 0.70879158\n",
      "Iteration 9, loss = 0.64477241\n",
      "Iteration 10, loss = 0.59107933\n",
      "Iteration 11, loss = 0.55130365\n",
      "Iteration 12, loss = 0.51529345\n",
      "Iteration 13, loss = 0.48739199\n",
      "Iteration 14, loss = 0.46850136\n",
      "Iteration 15, loss = 0.44199548\n",
      "Iteration 16, loss = 0.42674591\n",
      "Iteration 17, loss = 0.40851701\n",
      "Iteration 18, loss = 0.39849740\n",
      "Iteration 19, loss = 0.38606054\n",
      "Iteration 20, loss = 0.37398293\n",
      "Iteration 21, loss = 0.37020053\n",
      "Iteration 22, loss = 0.35667877\n",
      "Iteration 23, loss = 0.35101330\n",
      "Iteration 24, loss = 0.34348719\n",
      "Iteration 25, loss = 0.33963651\n",
      "Iteration 26, loss = 0.33512811\n",
      "Iteration 27, loss = 0.33058029\n",
      "Iteration 28, loss = 0.32666292\n",
      "Iteration 29, loss = 0.32129360\n",
      "Iteration 30, loss = 0.31801011\n",
      "Iteration 31, loss = 0.31404788\n",
      "Iteration 32, loss = 0.30869742\n",
      "Iteration 33, loss = 0.31213504\n",
      "Iteration 34, loss = 0.30539157\n",
      "Iteration 35, loss = 0.30848775\n",
      "Iteration 36, loss = 0.30261112\n",
      "Iteration 37, loss = 0.29456268\n",
      "Iteration 38, loss = 0.29887544\n",
      "Iteration 39, loss = 0.29133624\n",
      "Iteration 40, loss = 0.29487180\n",
      "Iteration 41, loss = 0.29050408\n",
      "Iteration 42, loss = 0.28653198\n",
      "Iteration 43, loss = 0.28682465\n",
      "Iteration 44, loss = 0.29163148\n",
      "Iteration 45, loss = 0.28122285\n",
      "Iteration 46, loss = 0.28028863\n",
      "Iteration 47, loss = 0.28586647\n",
      "Iteration 48, loss = 0.28146783\n",
      "Iteration 49, loss = 0.28030913\n",
      "Iteration 50, loss = 0.27865548\n",
      "Iteration 51, loss = 0.27813617\n",
      "Iteration 52, loss = 0.27892716\n",
      "Iteration 53, loss = 0.27132666\n",
      "Iteration 54, loss = 0.27144362\n",
      "Iteration 55, loss = 0.26946163\n",
      "Iteration 56, loss = 0.27974684\n",
      "Iteration 57, loss = 0.27304720\n",
      "Iteration 58, loss = 0.26650331\n",
      "Iteration 59, loss = 0.26717844\n",
      "Iteration 60, loss = 0.26779210\n",
      "Iteration 61, loss = 0.26329786\n",
      "Iteration 62, loss = 0.26703924\n",
      "Iteration 63, loss = 0.26455067\n",
      "Iteration 64, loss = 0.26233734\n",
      "Iteration 65, loss = 0.26431868\n",
      "Iteration 66, loss = 0.26250166\n",
      "Iteration 67, loss = 0.26108250\n",
      "Iteration 68, loss = 0.26888148\n",
      "Iteration 69, loss = 0.25931205\n",
      "Iteration 70, loss = 0.26970666\n",
      "Iteration 71, loss = 0.27170753\n",
      "Iteration 72, loss = 0.26225421\n",
      "Iteration 73, loss = 0.25800066\n",
      "Iteration 74, loss = 0.25432207\n",
      "Iteration 75, loss = 0.25658682\n",
      "Iteration 76, loss = 0.25415029\n",
      "Iteration 77, loss = 0.25132112\n",
      "Iteration 78, loss = 0.25213378\n",
      "Iteration 79, loss = 0.25435532\n",
      "Iteration 80, loss = 0.25115700\n",
      "Iteration 81, loss = 0.25055490\n",
      "Iteration 82, loss = 0.25120260\n",
      "Iteration 83, loss = 0.25357222\n",
      "Iteration 84, loss = 0.25522626\n",
      "Iteration 85, loss = 0.24902944\n",
      "Iteration 86, loss = 0.24931471\n",
      "Iteration 87, loss = 0.25974855\n",
      "Iteration 88, loss = 0.24675832\n",
      "Iteration 89, loss = 0.24845880\n",
      "Iteration 90, loss = 0.24594195\n",
      "Iteration 91, loss = 0.24690684\n",
      "Iteration 92, loss = 0.24526930\n",
      "Iteration 93, loss = 0.24580178\n",
      "Iteration 94, loss = 0.24578904\n",
      "Iteration 95, loss = 0.24551321\n",
      "Iteration 96, loss = 0.24708904\n",
      "Iteration 97, loss = 0.24351274\n",
      "Iteration 98, loss = 0.24427020\n",
      "Iteration 99, loss = 0.24517601\n",
      "Iteration 100, loss = 0.24607645\n",
      "Iteration 1, loss = 1.35663859\n",
      "Iteration 2, loss = 1.16221545\n",
      "Iteration 3, loss = 1.04431094\n",
      "Iteration 4, loss = 0.95233416\n",
      "Iteration 5, loss = 0.87775732\n",
      "Iteration 6, loss = 0.82151258\n",
      "Iteration 7, loss = 0.76729063\n",
      "Iteration 8, loss = 0.72821217\n",
      "Iteration 9, loss = 0.68002590\n",
      "Iteration 10, loss = 0.62305606\n",
      "Iteration 11, loss = 0.55924393\n",
      "Iteration 12, loss = 0.50131295\n",
      "Iteration 13, loss = 0.44800372\n",
      "Iteration 14, loss = 0.40366541\n",
      "Iteration 15, loss = 0.37093503\n",
      "Iteration 16, loss = 0.35274720\n",
      "Iteration 17, loss = 0.32837127\n",
      "Iteration 18, loss = 0.31346116\n",
      "Iteration 19, loss = 0.29867587\n",
      "Iteration 20, loss = 0.28928924\n",
      "Iteration 21, loss = 0.28424704\n",
      "Iteration 22, loss = 0.27774271\n",
      "Iteration 23, loss = 0.28279381\n",
      "Iteration 24, loss = 0.26422022\n",
      "Iteration 25, loss = 0.26067390\n",
      "Iteration 26, loss = 0.25742121\n",
      "Iteration 27, loss = 0.25487305\n",
      "Iteration 28, loss = 0.25171452\n",
      "Iteration 29, loss = 0.24766455\n",
      "Iteration 30, loss = 0.24775990\n",
      "Iteration 31, loss = 0.24408244\n",
      "Iteration 32, loss = 0.24126429\n",
      "Iteration 33, loss = 0.23957215\n",
      "Iteration 34, loss = 0.23686214\n",
      "Iteration 35, loss = 0.24167910\n",
      "Iteration 36, loss = 0.23463237\n",
      "Iteration 37, loss = 0.24068179\n",
      "Iteration 38, loss = 0.23375565\n",
      "Iteration 39, loss = 0.23363378\n",
      "Iteration 40, loss = 0.22854405\n",
      "Iteration 41, loss = 0.23147596\n",
      "Iteration 42, loss = 0.22414200\n",
      "Iteration 43, loss = 0.22900901\n",
      "Iteration 44, loss = 0.22501986\n",
      "Iteration 45, loss = 0.22302407\n",
      "Iteration 46, loss = 0.22512179\n",
      "Iteration 47, loss = 0.22083138\n",
      "Iteration 48, loss = 0.22053803\n",
      "Iteration 49, loss = 0.22143492\n",
      "Iteration 50, loss = 0.21948743\n",
      "Iteration 51, loss = 0.21824602\n",
      "Iteration 52, loss = 0.22608634\n",
      "Iteration 53, loss = 0.21979024\n",
      "Iteration 54, loss = 0.21557293\n",
      "Iteration 55, loss = 0.21806562\n",
      "Iteration 56, loss = 0.21594753\n",
      "Iteration 57, loss = 0.21606905\n",
      "Iteration 58, loss = 0.21604524\n",
      "Iteration 59, loss = 0.21976062\n",
      "Iteration 60, loss = 0.21376950\n",
      "Iteration 61, loss = 0.21536817\n",
      "Iteration 62, loss = 0.21561083\n",
      "Iteration 63, loss = 0.21412231\n",
      "Iteration 64, loss = 0.21262474\n",
      "Iteration 65, loss = 0.21496568\n",
      "Iteration 66, loss = 0.21847755\n",
      "Iteration 67, loss = 0.21425696\n",
      "Iteration 68, loss = 0.21621495\n",
      "Iteration 69, loss = 0.21086041\n",
      "Iteration 70, loss = 0.21279159\n",
      "Iteration 71, loss = 0.21375894\n",
      "Iteration 72, loss = 0.21301463\n",
      "Iteration 73, loss = 0.21090927\n",
      "Iteration 74, loss = 0.21364688\n",
      "Iteration 75, loss = 0.21621698\n",
      "Iteration 76, loss = 0.21478763\n",
      "Iteration 77, loss = 0.21015258\n",
      "Iteration 78, loss = 0.21076275\n",
      "Iteration 79, loss = 0.21690010\n",
      "Iteration 80, loss = 0.21309552\n",
      "Iteration 81, loss = 0.20749158\n",
      "Iteration 82, loss = 0.21078747\n",
      "Iteration 83, loss = 0.20807512\n",
      "Iteration 84, loss = 0.20797813\n",
      "Iteration 85, loss = 0.20771510\n",
      "Iteration 86, loss = 0.21191338\n",
      "Iteration 87, loss = 0.21298158\n",
      "Iteration 88, loss = 0.21299836\n",
      "Iteration 89, loss = 0.20655025\n",
      "Iteration 90, loss = 0.20939043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 91, loss = 0.20726251\n",
      "Iteration 92, loss = 0.20708867\n",
      "Iteration 93, loss = 0.20824643\n",
      "Iteration 94, loss = 0.20507617\n",
      "Iteration 95, loss = 0.20690594\n",
      "Iteration 96, loss = 0.20484725\n",
      "Iteration 97, loss = 0.20527654\n",
      "Iteration 98, loss = 0.21171767\n",
      "Iteration 99, loss = 0.20465742\n",
      "Iteration 100, loss = 0.21076827\n",
      "Train Accuracy: 91.0%\n",
      "Train Accuracy: 88.0%\n",
      "Train Accuracy: 88.0%\n",
      "INPUT:  [[1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "[{'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.268, 0.55 , 0.074, 0.108]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.262, 0.283, 0.205, 0.25 ]), 'nn': array([0.216, 0.628, 0.066, 0.089]), 'svc': array([0.361, 0.531, 0.024, 0.085]), 'nb': array([0.232, 0.759, 0.001, 0.008])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.084, 0.29 , 0.351, 0.274]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.095, 0.361, 0.187, 0.358]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.459, 0.091, 0.363, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.362, 0.096, 0.442, 0.1  ]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.105, 0.084, 0.154, 0.656]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.089, 0.094, 0.073, 0.744]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.675, 0.138, 0.079, 0.108]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.76 , 0.086, 0.065, 0.089]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.09 , 0.102, 0.608, 0.2  ]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.225, 0.239, 0.264, 0.272]), 'nn': array([0.083, 0.091, 0.733, 0.092]), 'svc': array([0.043, 0.031, 0.626, 0.3  ]), 'nb': array([0.01 , 0.045, 0.809, 0.136])}}, {'ensemble_proba': array([0.109, 0.547, 0.079, 0.264]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.232, 0.278, 0.218, 0.272]), 'nn': array([0.093, 0.516, 0.073, 0.318]), 'svc': array([0.093, 0.592, 0.023, 0.293]), 'nb': array([0.02 , 0.802, 0.002, 0.175])}}, {'ensemble_proba': array([0.084, 0.29 , 0.351, 0.274]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.095, 0.361, 0.187, 0.358]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.441, 0.23 , 0.093, 0.236]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.526, 0.105, 0.076, 0.293]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.459, 0.091, 0.363, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.362, 0.096, 0.442, 0.1  ]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.201, 0.591, 0.094, 0.114]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.267, 0.234, 0.251]), 'nn': array([0.106, 0.714, 0.072, 0.108]), 'svc': array([0.281, 0.603, 0.047, 0.069]), 'nb': array([0.17 , 0.779, 0.024, 0.027])}}, {'ensemble_proba': array([0.459, 0.091, 0.363, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.362, 0.096, 0.442, 0.1  ]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.212, 0.083, 0.554, 0.151]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.259, 0.217, 0.258, 0.267]), 'nn': array([0.1  , 0.099, 0.685, 0.116]), 'svc': array([0.245, 0.011, 0.609, 0.135]), 'nb': array([0.243, 0.007, 0.665, 0.085])}}, {'ensemble_proba': array([0.459, 0.091, 0.363, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.362, 0.096, 0.442, 0.1  ]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.171, 0.642, 0.093, 0.094]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.099, 0.745, 0.066, 0.09 ]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.171, 0.642, 0.093, 0.094]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.099, 0.745, 0.066, 0.09 ]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.171, 0.642, 0.093, 0.094]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.246, 0.282, 0.229, 0.242]), 'nn': array([0.099, 0.745, 0.066, 0.09 ]), 'svc': array([0.281, 0.607, 0.069, 0.042]), 'nb': array([0.057, 0.933, 0.006, 0.004])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.675, 0.138, 0.079, 0.108]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.76 , 0.086, 0.065, 0.089]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.459, 0.091, 0.363, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.362, 0.096, 0.442, 0.1  ]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.083, 0.141, 0.095, 0.682]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.213, 0.248, 0.218, 0.32 ]), 'nn': array([0.086, 0.099, 0.07 , 0.745]), 'svc': array([0.031, 0.193, 0.089, 0.687]), 'nb': array([0.001, 0.021, 0.003, 0.976])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.08 , 0.762, 0.065, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.666, 0.139, 0.112, 0.083]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.297, 0.244, 0.244, 0.215]), 'nn': array([0.744, 0.099, 0.067, 0.09 ]), 'svc': array([0.661, 0.195, 0.117, 0.027]), 'nb': array([0.962, 0.018, 0.02 , 0.   ])}}, {'ensemble_proba': array([0.087, 0.124, 0.652, 0.137]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.232, 0.238, 0.273, 0.258]), 'nn': array([0.085, 0.093, 0.708, 0.114]), 'svc': array([0.03 , 0.156, 0.683, 0.131]), 'nb': array([0.004, 0.01 , 0.943, 0.043])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.08 , 0.762, 0.065, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.186, 0.098, 0.084, 0.633]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.244, 0.236, 0.225, 0.295]), 'nn': array([0.104, 0.094, 0.072, 0.729]), 'svc': array([0.296, 0.046, 0.026, 0.632]), 'nb': array([0.1  , 0.014, 0.011, 0.875])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.441, 0.23 , 0.093, 0.236]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.526, 0.105, 0.076, 0.293]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.125, 0.116, 0.161, 0.597]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.11 , 0.168, 0.175, 0.547]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.629, 0.099, 0.09 , 0.181]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.27 , 0.238, 0.223, 0.269]), 'nn': array([0.755, 0.089, 0.066, 0.09 ]), 'svc': array([0.625, 0.025, 0.05 , 0.3  ]), 'nb': array([0.868, 0.046, 0.02 , 0.066])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.08 , 0.762, 0.065, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.105, 0.084, 0.154, 0.656]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.089, 0.094, 0.073, 0.744]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.394, 0.308, 0.211, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.262, 0.255, 0.256, 0.227]), 'nn': array([0.561, 0.247, 0.103, 0.09 ]), 'svc': array([0.368, 0.416, 0.19 , 0.026]), 'nb': array([0.387, 0.316, 0.294, 0.003])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.107, 0.076, 0.647, 0.169]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.246, 0.205, 0.284, 0.265]), 'nn': array([0.083, 0.089, 0.738, 0.09 ]), 'svc': array([0.085, 0.01 , 0.608, 0.296]), 'nb': array([0.013, 0.   , 0.96 , 0.027])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.08 , 0.762, 0.065, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.157, 0.085, 0.676, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.269, 0.209, 0.312, 0.21 ]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.271, 0.044, 0.657, 0.027]), 'nb': array([0.007, 0.   , 0.993, 0.   ])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.578, 0.087, 0.099, 0.236]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.272, 0.224, 0.227, 0.277]), 'nn': array([0.679, 0.097, 0.078, 0.147]), 'svc': array([0.555, 0.016, 0.068, 0.361]), 'nb': array([0.808, 0.012, 0.023, 0.157])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.434, 0.137, 0.075, 0.354]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.248, 0.203, 0.295]), 'nn': array([0.618, 0.105, 0.073, 0.204]), 'svc': array([0.508, 0.09 , 0.024, 0.378]), 'nb': array([0.355, 0.106, 0.001, 0.538])}}, {'ensemble_proba': array([0.085, 0.158, 0.646, 0.111]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.084, 0.103, 0.718, 0.094]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.09 , 0.102, 0.608, 0.2  ]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.225, 0.239, 0.264, 0.272]), 'nn': array([0.083, 0.091, 0.733, 0.092]), 'svc': array([0.043, 0.031, 0.626, 0.3  ]), 'nb': array([0.01 , 0.045, 0.809, 0.136])}}, {'ensemble_proba': array([0.125, 0.116, 0.161, 0.597]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.11 , 0.168, 0.175, 0.547]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.125, 0.116, 0.161, 0.597]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.11 , 0.168, 0.175, 0.547]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.085, 0.158, 0.646, 0.111]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.084, 0.103, 0.718, 0.094]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.08 , 0.762, 0.065, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.08 , 0.762, 0.065, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.441, 0.23 , 0.093, 0.236]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.526, 0.105, 0.076, 0.293]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.657, 0.075, 0.112, 0.155]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.295, 0.204, 0.24 , 0.261]), 'nn': array([0.757, 0.086, 0.069, 0.089]), 'svc': array([0.608, 0.011, 0.121, 0.26 ]), 'nb': array([0.968, 0.   , 0.02 , 0.011])}}, {'ensemble_proba': array([0.157, 0.085, 0.676, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.269, 0.209, 0.312, 0.21 ]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.271, 0.044, 0.657, 0.027]), 'nb': array([0.007, 0.   , 0.993, 0.   ])}}, {'ensemble_proba': array([0.165, 0.449, 0.132, 0.255]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.252, 0.244, 0.255]), 'nn': array([0.123, 0.544, 0.091, 0.243]), 'svc': array([0.082, 0.591, 0.037, 0.291]), 'nb': array([0.205, 0.41 , 0.155, 0.23 ])}}, {'ensemble_proba': array([0.675, 0.085, 0.159, 0.081]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.323, 0.208, 0.261, 0.208]), 'nn': array([0.76 , 0.086, 0.066, 0.088]), 'svc': array([0.636, 0.045, 0.293, 0.026]), 'nb': array([0.981, 0.   , 0.019, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.085, 0.17 , 0.09 , 0.655]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.211, 0.263, 0.214, 0.313]), 'nn': array([0.087, 0.102, 0.07 , 0.741]), 'svc': array([0.041, 0.223, 0.075, 0.662]), 'nb': array([0.001, 0.091, 0.003, 0.905])}}, {'ensemble_proba': array([0.125, 0.116, 0.161, 0.597]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.11 , 0.168, 0.175, 0.547]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.083, 0.141, 0.095, 0.682]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.213, 0.248, 0.218, 0.32 ]), 'nn': array([0.086, 0.099, 0.07 , 0.745]), 'svc': array([0.031, 0.193, 0.089, 0.687]), 'nb': array([0.001, 0.021, 0.003, 0.976])}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 0, 3, 2, 0, 3, 0, 2, 1, 2, 0, 0, 2, 3, 1, 0, 0, 2, 0, 1,\n",
       "       2, 3, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 0, 0, 2, 0, 1, 3, 1, 0, 2,\n",
       "       3, 1, 3, 1, 0, 3, 0, 1, 0, 3, 3, 3, 0, 0, 0, 2, 1, 2, 1, 1, 2, 0,\n",
       "       0, 0, 0, 2, 1, 3, 2, 2, 3, 3, 1, 3, 2, 1, 3, 1, 1, 0, 3, 3, 0, 2,\n",
       "       1, 0, 1, 3, 3, 2, 1, 3, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Classifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26307ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  [[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[{'ensemble_proba': array([0.459, 0.091, 0.363, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.362, 0.096, 0.442, 0.1  ]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.124, 0.128, 0.664, 0.084]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.248, 0.245, 0.289, 0.218]), 'nn': array([0.09 , 0.092, 0.729, 0.09 ]), 'svc': array([0.143, 0.156, 0.674, 0.027]), 'nb': array([0.013, 0.021, 0.965, 0.   ])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.085, 0.158, 0.646, 0.111]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.227, 0.249, 0.275, 0.25 ]), 'nn': array([0.084, 0.103, 0.718, 0.094]), 'svc': array([0.028, 0.223, 0.656, 0.093]), 'nb': array([0.002, 0.056, 0.934, 0.007])}}, {'ensemble_proba': array([0.441, 0.23 , 0.093, 0.236]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.254, 0.255, 0.232, 0.259]), 'nn': array([0.526, 0.105, 0.076, 0.293]), 'svc': array([0.493, 0.343, 0.025, 0.138]), 'nb': array([0.489, 0.217, 0.039, 0.256])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.16 , 0.086, 0.673, 0.082]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.27 , 0.209, 0.309, 0.211]), 'nn': array([0.081, 0.089, 0.741, 0.089]), 'svc': array([0.274, 0.044, 0.654, 0.027]), 'nb': array([0.015, 0.   , 0.985, 0.   ])}}, {'ensemble_proba': array([0.165, 0.449, 0.132, 0.255]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.248, 0.252, 0.244, 0.255]), 'nn': array([0.123, 0.544, 0.091, 0.243]), 'svc': array([0.082, 0.591, 0.037, 0.291]), 'nb': array([0.205, 0.41 , 0.155, 0.23 ])}}, {'ensemble_proba': array([0.675, 0.138, 0.079, 0.108]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.289, 0.244, 0.222, 0.245]), 'nn': array([0.76 , 0.086, 0.065, 0.089]), 'svc': array([0.667, 0.213, 0.026, 0.094]), 'nb': array([0.983, 0.01 , 0.002, 0.005])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.08 , 0.762, 0.065, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}, {'ensemble_proba': array([0.084, 0.29 , 0.351, 0.274]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.095, 0.361, 0.187, 0.358]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.08 , 0.105, 0.229, 0.586]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.203, 0.24 , 0.248, 0.309]), 'nn': array([0.092, 0.115, 0.214, 0.579]), 'svc': array([0.026, 0.045, 0.326, 0.602]), 'nb': array([0.   , 0.02 , 0.127, 0.853])}}, {'ensemble_proba': array([0.105, 0.084, 0.154, 0.656]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.233, 0.228, 0.233, 0.306]), 'nn': array([0.089, 0.094, 0.073, 0.744]), 'svc': array([0.091, 0.012, 0.277, 0.62 ]), 'nb': array([0.008, 0.004, 0.032, 0.955])}}, {'ensemble_proba': array([0.629, 0.099, 0.09 , 0.181]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.27 , 0.238, 0.223, 0.269]), 'nn': array([0.755, 0.089, 0.066, 0.09 ]), 'svc': array([0.625, 0.025, 0.05 , 0.3  ]), 'nb': array([0.868, 0.046, 0.02 , 0.066])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.088, 0.66 , 0.073, 0.179]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.205, 0.311, 0.196, 0.288]), 'nn': array([0.08 , 0.762, 0.065, 0.093]), 'svc': array([0.068, 0.602, 0.029, 0.301]), 'nb': array([0.   , 0.963, 0.   , 0.037])}}, {'ensemble_proba': array([0.459, 0.091, 0.363, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.362, 0.096, 0.442, 0.1  ]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}, {'ensemble_proba': array([0.125, 0.116, 0.161, 0.597]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.238, 0.234, 0.237, 0.291]), 'nn': array([0.11 , 0.168, 0.175, 0.547]), 'svc': array([0.107, 0.033, 0.184, 0.676]), 'nb': array([0.046, 0.03 , 0.049, 0.875])}}, {'ensemble_proba': array([0.084, 0.29 , 0.351, 0.274]), 'ensemble_prediction': np.int64(2), 'individual_probas': {'lr': array([0.212, 0.26 , 0.257, 0.271]), 'nn': array([0.095, 0.361, 0.187, 0.358]), 'svc': array([0.028, 0.241, 0.513, 0.218]), 'nb': array([0.001, 0.3  , 0.448, 0.251])}}, {'ensemble_proba': array([0.084, 0.287, 0.076, 0.553]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.196, 0.287, 0.19 , 0.327]), 'nn': array([0.088, 0.273, 0.071, 0.568]), 'svc': array([0.051, 0.255, 0.043, 0.651]), 'nb': array([0.   , 0.333, 0.   , 0.667])}}, {'ensemble_proba': array([0.084, 0.165, 0.076, 0.675]), 'ensemble_prediction': np.int64(3), 'individual_probas': {'lr': array([0.197, 0.271, 0.193, 0.338]), 'nn': array([0.086, 0.094, 0.069, 0.751]), 'svc': array([0.052, 0.242, 0.043, 0.663]), 'nb': array([0.   , 0.052, 0.   , 0.948])}}, {'ensemble_proba': array([0.093, 0.576, 0.072, 0.259]), 'ensemble_prediction': np.int64(1), 'individual_probas': {'lr': array([0.207, 0.295, 0.2  , 0.298]), 'nn': array([0.083, 0.684, 0.067, 0.166]), 'svc': array([0.083, 0.583, 0.022, 0.312]), 'nb': array([0.   , 0.741, 0.   , 0.259])}}]\n",
      "Test Accuracy: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "accuracy = np.mean(np.array(preds) == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea208645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  [[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[{'ensemble_proba': array([0.459, 0.091, 0.363, 0.087]), 'ensemble_prediction': np.int64(0), 'individual_probas': {'lr': array([0.286, 0.219, 0.275, 0.221]), 'nn': array([0.362, 0.096, 0.442, 0.1  ]), 'svc': array([0.603, 0.046, 0.324, 0.027]), 'nb': array([0.585, 0.001, 0.413, 0.001])}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pacman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
