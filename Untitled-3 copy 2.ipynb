{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7670f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.71671067\n",
      "Iteration 2, loss = 1.35900568\n",
      "Iteration 3, loss = 1.15582971\n",
      "Iteration 4, loss = 1.00013552\n",
      "Iteration 5, loss = 0.88403242\n",
      "Iteration 6, loss = 0.78124905\n",
      "Iteration 7, loss = 0.70294091\n",
      "Iteration 8, loss = 0.62773547\n",
      "Iteration 9, loss = 0.56587618\n",
      "Iteration 10, loss = 0.51268993\n",
      "Iteration 11, loss = 0.47250808\n",
      "Iteration 12, loss = 0.43762457\n",
      "Iteration 13, loss = 0.41076725\n",
      "Iteration 14, loss = 0.39100146\n",
      "Iteration 15, loss = 0.37603064\n",
      "Iteration 16, loss = 0.35644102\n",
      "Iteration 17, loss = 0.34850532\n",
      "Iteration 18, loss = 0.33577824\n",
      "Iteration 19, loss = 0.33025963\n",
      "Iteration 20, loss = 0.32596703\n",
      "Iteration 21, loss = 0.31802031\n",
      "Iteration 22, loss = 0.31053190\n",
      "Iteration 23, loss = 0.30537302\n",
      "Iteration 24, loss = 0.30380070\n",
      "Iteration 25, loss = 0.30184543\n",
      "Iteration 26, loss = 0.29543012\n",
      "Iteration 27, loss = 0.29193183\n",
      "Iteration 28, loss = 0.28727769\n",
      "Iteration 29, loss = 0.28491775\n",
      "Iteration 30, loss = 0.29012489\n",
      "Iteration 31, loss = 0.28205304\n",
      "Iteration 32, loss = 0.27936201\n",
      "Iteration 33, loss = 0.27616311\n",
      "Iteration 34, loss = 0.27862876\n",
      "Iteration 35, loss = 0.27731553\n",
      "Iteration 36, loss = 0.27068162\n",
      "Iteration 37, loss = 0.27041754\n",
      "Iteration 38, loss = 0.26813128\n",
      "Iteration 39, loss = 0.26627359\n",
      "Iteration 40, loss = 0.26728994\n",
      "Iteration 41, loss = 0.26607133\n",
      "Iteration 42, loss = 0.26604004\n",
      "Iteration 43, loss = 0.26076901\n",
      "Iteration 44, loss = 0.25936948\n",
      "Iteration 45, loss = 0.26008207\n",
      "Iteration 46, loss = 0.25947805\n",
      "Iteration 47, loss = 0.26010040\n",
      "Iteration 48, loss = 0.25947100\n",
      "Iteration 49, loss = 0.26222389\n",
      "Iteration 50, loss = 0.25506149\n",
      "Iteration 51, loss = 0.25668932\n",
      "Iteration 52, loss = 0.25426085\n",
      "Iteration 53, loss = 0.25189768\n",
      "Iteration 54, loss = 0.25225749\n",
      "Iteration 55, loss = 0.25048558\n",
      "Iteration 56, loss = 0.25105205\n",
      "Iteration 57, loss = 0.25114475\n",
      "Iteration 58, loss = 0.24733362\n",
      "Iteration 59, loss = 0.24754008\n",
      "Iteration 60, loss = 0.25088046\n",
      "Iteration 61, loss = 0.24901658\n",
      "Iteration 62, loss = 0.24865624\n",
      "Iteration 63, loss = 0.25450827\n",
      "Iteration 64, loss = 0.24629793\n",
      "Iteration 65, loss = 0.24297772\n",
      "Iteration 66, loss = 0.25115194\n",
      "Iteration 67, loss = 0.24185882\n",
      "Iteration 68, loss = 0.24859871\n",
      "Iteration 69, loss = 0.25334130\n",
      "Iteration 70, loss = 0.25057496\n",
      "Iteration 71, loss = 0.24726094\n",
      "Iteration 72, loss = 0.24120416\n",
      "Iteration 73, loss = 0.24778829\n",
      "Iteration 74, loss = 0.24476598\n",
      "Iteration 75, loss = 0.24490133\n",
      "Iteration 76, loss = 0.24608238\n",
      "Iteration 77, loss = 0.24344376\n",
      "Iteration 78, loss = 0.24514209\n",
      "Iteration 79, loss = 0.24058803\n",
      "Iteration 80, loss = 0.24053466\n",
      "Iteration 81, loss = 0.23897693\n",
      "Iteration 82, loss = 0.24314682\n",
      "Iteration 83, loss = 0.23647618\n",
      "Iteration 84, loss = 0.24309757\n",
      "Iteration 85, loss = 0.23984836\n",
      "Iteration 86, loss = 0.23963714\n",
      "Iteration 87, loss = 0.24694758\n",
      "Iteration 88, loss = 0.23649758\n",
      "Iteration 89, loss = 0.23445039\n",
      "Iteration 90, loss = 0.24183101\n",
      "Iteration 91, loss = 0.24180577\n",
      "Iteration 92, loss = 0.23488054\n",
      "Iteration 93, loss = 0.23546494\n",
      "Iteration 94, loss = 0.23588760\n",
      "Iteration 95, loss = 0.23691867\n",
      "Iteration 96, loss = 0.24423020\n",
      "Iteration 97, loss = 0.23620454\n",
      "Iteration 98, loss = 0.23284519\n",
      "Iteration 99, loss = 0.23401000\n",
      "Iteration 100, loss = 0.23394979\n",
      "Train Accuracy: 92.0%\n",
      "Train Accuracy: 89.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 0, 3, 1, 0, 3, 0, 2, 1, 1, 0, 0, 2, 3, 1, 0, 0, 2, 0, 1,\n",
       "       2, 3, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 0, 0, 2, 0, 1, 3, 1, 0, 2,\n",
       "       3, 1, 3, 1, 0, 3, 0, 1, 0, 3, 3, 3, 0, 0, 0, 2, 1, 2, 1, 1, 2, 0,\n",
       "       0, 0, 0, 2, 1, 3, 2, 2, 3, 3, 1, 3, 2, 1, 3, 1, 1, 0, 3, 3, 0, 2,\n",
       "       1, 0, 1, 3, 3, 2, 1, 3, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import classifierAgents\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "file = '/Users/youssefawad/Documents/Kings/term_2/6CCS3ML1_Machine_Learning/coursework/cw1_pacman/good-moves.txt'\n",
    "\n",
    "data, target = classifierAgents.loadData(file)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "from classifier import Classifier\n",
    "\n",
    "clf = Classifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbd4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "accuracy = np.mean(preds == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b9e8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f6f963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d8e6d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.48998823\n",
      "Iteration 2, loss = 1.34834534\n",
      "Iteration 3, loss = 1.19230826\n",
      "Iteration 4, loss = 1.02886394\n",
      "Iteration 5, loss = 0.86384295\n",
      "Iteration 6, loss = 0.72642996\n",
      "Iteration 7, loss = 0.61441951\n",
      "Iteration 8, loss = 0.54101617\n",
      "Iteration 9, loss = 0.48821141\n",
      "Iteration 10, loss = 0.44866307\n",
      "Iteration 11, loss = 0.42207928\n",
      "Iteration 12, loss = 0.39804099\n",
      "Iteration 13, loss = 0.38580604\n",
      "Iteration 14, loss = 0.36579286\n",
      "Iteration 15, loss = 0.35692828\n",
      "Iteration 16, loss = 0.34651099\n",
      "Iteration 17, loss = 0.33400801\n",
      "Iteration 18, loss = 0.33831865\n",
      "Iteration 19, loss = 0.32838996\n",
      "Iteration 20, loss = 0.32093133\n",
      "Iteration 21, loss = 0.31292670\n",
      "Iteration 22, loss = 0.30993836\n",
      "Iteration 23, loss = 0.30681287\n",
      "Iteration 24, loss = 0.30941211\n",
      "Iteration 25, loss = 0.30327841\n",
      "Iteration 26, loss = 0.29403871\n",
      "Iteration 27, loss = 0.29625842\n",
      "Iteration 28, loss = 0.29600985\n",
      "Iteration 29, loss = 0.29120287\n",
      "Iteration 30, loss = 0.28721179\n",
      "Iteration 31, loss = 0.28562760\n",
      "Iteration 32, loss = 0.28587891\n",
      "Iteration 33, loss = 0.28906597\n",
      "Iteration 34, loss = 0.28144213\n",
      "Iteration 35, loss = 0.27841524\n",
      "Iteration 36, loss = 0.27574694\n",
      "Iteration 37, loss = 0.27481002\n",
      "Iteration 38, loss = 0.27952260\n",
      "Iteration 39, loss = 0.28216200\n",
      "Iteration 40, loss = 0.27139513\n",
      "Iteration 41, loss = 0.27391662\n",
      "Iteration 42, loss = 0.27395683\n",
      "Iteration 43, loss = 0.26943636\n",
      "Iteration 44, loss = 0.26574075\n",
      "Iteration 45, loss = 0.26601049\n",
      "Iteration 46, loss = 0.26989743\n",
      "Iteration 47, loss = 0.26311768\n",
      "Iteration 48, loss = 0.26523737\n",
      "Iteration 49, loss = 0.26073645\n",
      "Iteration 50, loss = 0.26064130\n",
      "Iteration 51, loss = 0.26083535\n",
      "Iteration 52, loss = 0.25855465\n",
      "Iteration 53, loss = 0.25985249\n",
      "Iteration 54, loss = 0.25863816\n",
      "Iteration 55, loss = 0.25781345\n",
      "Iteration 56, loss = 0.25616425\n",
      "Iteration 57, loss = 0.25291644\n",
      "Iteration 58, loss = 0.26213022\n",
      "Iteration 59, loss = 0.25902600\n",
      "Iteration 60, loss = 0.25386889\n",
      "Iteration 61, loss = 0.25358849\n",
      "Iteration 62, loss = 0.25553281\n",
      "Iteration 63, loss = 0.25608860\n",
      "Iteration 64, loss = 0.24974802\n",
      "Iteration 65, loss = 0.25458229\n",
      "Iteration 66, loss = 0.25427963\n",
      "Iteration 67, loss = 0.25255738\n",
      "Iteration 68, loss = 0.24915225\n",
      "Iteration 69, loss = 0.24842010\n",
      "Iteration 70, loss = 0.24526615\n",
      "Iteration 71, loss = 0.24654822\n",
      "Iteration 72, loss = 0.24770309\n",
      "Iteration 73, loss = 0.24876212\n",
      "Iteration 74, loss = 0.24576172\n",
      "Iteration 75, loss = 0.24540557\n",
      "Iteration 76, loss = 0.24711619\n",
      "Iteration 77, loss = 0.24386969\n",
      "Iteration 78, loss = 0.24067216\n",
      "Iteration 79, loss = 0.24350609\n",
      "Iteration 80, loss = 0.24559255\n",
      "Iteration 81, loss = 0.24161134\n",
      "Iteration 82, loss = 0.24257161\n",
      "Iteration 83, loss = 0.24112855\n",
      "Iteration 84, loss = 0.24256892\n",
      "Iteration 85, loss = 0.24206710\n",
      "Iteration 86, loss = 0.24121370\n",
      "Iteration 87, loss = 0.24385189\n",
      "Iteration 88, loss = 0.24144108\n",
      "Iteration 89, loss = 0.23997471\n",
      "Iteration 90, loss = 0.24883870\n",
      "Iteration 91, loss = 0.24470000\n",
      "Iteration 92, loss = 0.24413365\n",
      "Iteration 93, loss = 0.23991030\n",
      "Iteration 94, loss = 0.23786591\n",
      "Iteration 95, loss = 0.23856118\n",
      "Iteration 96, loss = 0.24297891\n",
      "Iteration 97, loss = 0.23639987\n",
      "Iteration 98, loss = 0.23628092\n",
      "Iteration 99, loss = 0.24022658\n",
      "Iteration 100, loss = 0.23770234\n",
      "Train Accuracy: 91.0%\n",
      "Train Accuracy: 89.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pacman/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 0, 3, 3, 0, 3, 0, 2, 1, 3, 0, 0, 2, 3, 1, 0, 0, 2, 0, 1,\n",
       "       2, 3, 1, 0, 0, 1, 1, 1, 0, 1, 2, 1, 2, 0, 0, 2, 0, 1, 3, 1, 0, 2,\n",
       "       3, 1, 3, 1, 0, 3, 0, 1, 0, 3, 3, 3, 0, 0, 0, 2, 1, 2, 1, 1, 2, 0,\n",
       "       0, 0, 0, 2, 1, 3, 2, 2, 3, 3, 1, 3, 2, 1, 3, 1, 1, 0, 3, 3, 0, 2,\n",
       "       1, 0, 1, 3, 3, 2, 1, 3, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Classifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26307ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "accuracy = np.mean(np.array(preds) == y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea208645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pacman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
